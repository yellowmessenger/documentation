<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-platform_concepts/studio/tools" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">Tools and settings | yellow.ai</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" property="og:image" content="https://docs.yellow.ai/img/og_img.png"><meta data-rh="true" name="twitter:image" content="https://docs.yellow.ai/img/og_img.png"><meta data-rh="true" property="og:url" content="https://docs.yellow.ai/docs/platform_concepts/studio/tools"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="twitter:card" content="summary"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Tools and settings | yellow.ai"><meta data-rh="true" name="description" content="You can find advanced settings in the tools section, that will help you to finely adjust your AI-agent&#x27;s performance. You can calibrate language understanding through NLU, configure conversational behavior, add constant values that do not change in any conversations, and prepare for upcoming Voice capabilities. These tools collectively elevate your AI-agent&#x27;s performance and user engagement."><meta data-rh="true" property="og:description" content="You can find advanced settings in the tools section, that will help you to finely adjust your AI-agent&#x27;s performance. You can calibrate language understanding through NLU, configure conversational behavior, add constant values that do not change in any conversations, and prepare for upcoming Voice capabilities. These tools collectively elevate your AI-agent&#x27;s performance and user engagement."><link data-rh="true" rel="icon" href="/img/favicon.svg"><link data-rh="true" rel="canonical" href="https://docs.yellow.ai/docs/platform_concepts/studio/tools"><link data-rh="true" rel="alternate" href="https://docs.yellow.ai/docs/platform_concepts/studio/tools" hreflang="en"><link data-rh="true" rel="alternate" href="https://docs.yellow.ai/docs/platform_concepts/studio/tools" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://LWOORM11IH-dsn.algolia.net" crossorigin="anonymous"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Automation","item":"https://docs.yellow.ai/docs/platform_concepts/studio/overview"},{"@type":"ListItem","position":2,"name":"Rule-based conversations (Non-AI agent)","item":"https://docs.yellow.ai/docs/platform_concepts/studio/build/chatbot"},{"@type":"ListItem","position":3,"name":"Tools & settings","item":"https://docs.yellow.ai/docs/platform_concepts/studio/tools"}]}</script><link rel="preconnect" href="https://www.google-analytics.com">
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","G-NDQJKXFGTV","auto"),ga("send","pageview")</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-NDQJKXFGTV"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-NDQJKXFGTV",{anonymize_ip:!0})</script>





<link rel="search" type="application/opensearchdescription+xml" title="yellow.ai" href="/opensearch.xml">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/remixicon@2.5.0/fonts/remixicon.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Roboto&family=Source+Sans+Pro&display=swap">
<script src="/js/FeedbackFooter.js"></script>
<script src="/js/bot.js"></script><link rel="stylesheet" href="/assets/css/styles.958bef79.css">
<script src="/assets/js/runtime~main.126d87ee.js" defer="defer"></script>
<script src="/assets/js/main.7ab11fca.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light";var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/Yai-logo-yellow.svg"><link rel="preload" as="image" href="/img/Yellow.ai_Logo-1.png"><link rel="preload" as="image" href="https://i.imgur.com/YrLTZ16.png"><link rel="preload" as="image" href="https://i.imgur.com/F5rVJIF.png"><link rel="preload" as="image" href="https://i.imgur.com/U0iekzn.png"><link rel="preload" as="image" href="https://i.imgur.com/XJpwl4I.png"><link rel="preload" as="image" href="https://i.imgur.com/lDz7NrX.png"><link rel="preload" as="image" href="https://i.imgur.com/3Kt7IiD.png"><link rel="preload" as="image" href="https://i.imgur.com/p1xK8Sq.png"><link rel="preload" as="image" href="https://i.imgur.com/fsJZA3R.png"><link rel="preload" as="image" href="https://i.imgur.com/tt2P4FO.jpg"><link rel="preload" as="image" href="https://i.imgur.com/T1jOHPX.jpg"><link rel="preload" as="image" href="https://i.imgur.com/VZalCux.png"><link rel="preload" as="image" href="https://i.imgur.com/Ix9CTWR.png"><link rel="preload" as="image" href="https://i.imgur.com/K8qsb52.png"><link rel="preload" as="image" href="https://i.imgur.com/FpRIio0.png"><link rel="preload" as="image" href="https://i.imgur.com/7mMh5Nz.png"><link rel="preload" as="image" href="https://i.imgur.com/Hvu2ioK.png"><link rel="preload" as="image" href="https://i.imgur.com/Ik9ozKr.png"><link rel="preload" as="image" href="https://i.imgur.com/7DM473O.png"><link rel="preload" as="image" href="https://i.imgur.com/k5bc5Tz.png"><link rel="preload" as="image" href="https://i.imgur.com/aok3dur.png"><link rel="preload" as="image" href="https://i.imgur.com/vaIpqm5.png"><link rel="preload" as="image" href="https://i.imgur.com/CCIjO7s.png"><link rel="preload" as="image" href="https://i.imgur.com/ikUXSHT.png"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/Yai-logo-yellow.svg" alt="yellow.ai" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/Yellow.ai_Logo-1.png" alt="yellow.ai" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/platform_concepts/getting-started">Help Docs</a><a class="navbar__item navbar__link" href="/docs/cookbooks/getting_started">Use Case Guides</a><a class="navbar__item navbar__link" href="/api">API Reference</a><a class="navbar__item navbar__link" href="/docs/updates/overview">What&#x27;s New</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/docs/tutorials/basics">Videos</a><a href="https://community.yellow.ai" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Community</a><a href="https://cloud.yellow.ai/auth/signup?utm_source=SupportDocs&amp;utm_medium=doc_navbar&amp;utm_campaign=docs_april_23" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link free-signup">Try for free</a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/platform_concepts/getting-started">Get started with yellow.ai</a><button aria-label="Expand sidebar category &#x27;Get started with yellow.ai&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/docs/platform_concepts/studio/overview">Automation</a><button aria-label="Collapse sidebar category &#x27;Automation&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/platform_concepts/AIAgent/aiagent-architecture">Build your AI agent</a><button aria-label="Expand sidebar category &#x27;Build your AI agent&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" tabindex="0" href="/docs/platform_concepts/studio/build/chatbot">Rule-based conversations (Non-AI agent)</a><button aria-label="Collapse sidebar category &#x27;Rule-based conversations (Non-AI agent)&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/platform_concepts/studio/build/create_chatbot">Create &amp; configure chatbot</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/platform_concepts/studio/build/Flows/flows-overview">Configure chatbot conversations</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/docs/platform_concepts/studio/train/intents">Training chatbot data </a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/platform_concepts/studio/train/intents">Intents</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/platform_concepts/studio/train/entities">Entities</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/platform_concepts/studio/train/add-faqs">FAQ AI-agents</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/platform_concepts/studio/train/what-is-document-cognition">Documents</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/platform_concepts/studio/train/synonyms">Synonyms</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/platform_concepts/studio/train/smalltalk">Small talk</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/platform_concepts/studio/train/add-contextual-response">Contextual Responses</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/platform_concepts/studio/tools">Tools &amp; settings</a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/platform_concepts/studio/train/orchllm">Orchestrator LLM</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/platform_concepts/studio/api/add-api">Connect external APIs to Chatbot/AI agent</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/platform_concepts/studio/test-and-publish-bot/bot-logs">Test and publish Chatbot</a></div></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/platform_concepts/studio/LLM-central-configuration">LLM configuration</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/platform_concepts/studio/build/workflows">Automate Inbox Workflows</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" tabindex="0" href="/docs/platform_concepts/engagement/cdp/user_data/data_capture_convers">Understand how user records are handled in AI and Non-AI agent</a><button aria-label="Expand sidebar category &#x27;Understand how user records are handled in AI and Non-AI agent&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/platform_concepts/studio/studio-faqs">Chatbot FAQs</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/platform_concepts/get_started/add-bot-collaborators">User &amp; account management</a><button aria-label="Expand sidebar category &#x27;User &amp; account management&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/platform_concepts/studio/kb/overview">Knowledge hub</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/platform_concepts/inbox">Inbox</a><button aria-label="Expand sidebar category &#x27;Inbox&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/platform_concepts/engagement/cdp/overview">User 360</a><button aria-label="Expand sidebar category &#x27;User 360&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/platform_concepts/engagement/engage">Engage</a><button aria-label="Expand sidebar category &#x27;Engage&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/platform_concepts/analyze/analyseintro">Analyze</a><button aria-label="Expand sidebar category &#x27;Analyze&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/platform_concepts/growth/introductiontoinsights">Insights</a><button aria-label="Expand sidebar category &#x27;Insights&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/platform_concepts/channelConfiguration/overview">Channels</a><button aria-label="Expand sidebar category &#x27;Channels&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/platform_concepts/appConfiguration/overview">Integrations</a><button aria-label="Expand sidebar category &#x27;Integrations&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/cookbooks/voice-as-channel/vbintro">AI Voice agent builder</a><button aria-label="Expand sidebar category &#x27;AI Voice agent builder&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/platform_concepts/emailAutomation">Others</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/docs/platform_concepts/studio/overview"><span>Automation</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/docs/platform_concepts/studio/build/chatbot"><span>Rule-based conversations (Non-AI agent)</span></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Training chatbot data </span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Tools &amp; settings</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Tools and settings</h1></header><p>You can find advanced settings in the tools section, that will help you to finely adjust your AI-agent&#x27;s performance. You can calibrate language understanding through NLU, configure conversational behavior, add constant values that do not change in any conversations, and prepare for upcoming Voice capabilities. These tools collectively elevate your AI-agent&#x27;s performance and user engagement.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="access-tools">Access tools<a href="#access-tools" class="hash-link" aria-label="Direct link to Access tools" title="Direct link to Access tools">​</a></h2>
<p>To access the tools section:</p>
<ol>
<li>
<p>Go to <strong>Automation</strong> &gt; <strong>Train</strong> &gt; <strong>Intents</strong> &gt; <strong>Tools</strong></p>
<p><img decoding="async" loading="lazy" src="https://imgur.com/e4CgoyZ.png" alt="" class="img_ev3q"></p>
</li>
</ol>
<p>The tools section consists of five segments:</p>
<img src="https://i.imgur.com/YrLTZ16.png" alt="drawing" width="60%">
<table><thead><tr><th>Tool</th><th>Description</th></tr></thead><tbody><tr><td>Test your bot</td><td>Analyse user-input sentences.</td></tr><tr><td>Conversation</td><td>Tailor <strong>Conversation settings</strong>, such as <strong>Behavior</strong>, <strong>Intelligent switching</strong>, <strong>Step validation</strong>, and <strong>Auto skip settings</strong>.</td></tr><tr><td>NLU</td><td>Customize technical specifics based on training.</td></tr><tr><td>Constants</td><td>Incorporate constant values stored in the database, such as names or filenames, ensuring continuity throughout interactions.</td></tr><tr><td>Voice</td><td>Adjust settings linked to the <strong>Voice</strong> feature on our platform.</td></tr></tbody></table>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="test-your-bot">Test your bot<a href="#test-your-bot" class="hash-link" aria-label="Direct link to Test your bot" title="Direct link to Test your bot">​</a></h2>
<p>This section helps you check whether the associated intent will be triggered or not. The AI-agent utilizes prediction to determine the intention behind the input and evaluates the accuracy of the prediction. It also identifies the AI-agent&#x27;s response based on the input text, including automatically recognized entities.</p>
<p>For instance, when you type an utterance in the &quot;What user says?&quot; section, you&#x27;ll see the corresponding response and its confidence level displayed along with the related flow.</p>
<img src="https://i.imgur.com/F5rVJIF.png" alt="drawing" width="60%">
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="response-parameters">Response parameters<a href="#response-parameters" class="hash-link" aria-label="Direct link to Response parameters" title="Direct link to Response parameters">​</a></h3>
<p>The following is a comprehensive description of the parameters in the response received for the typed input.</p>
<table><thead><tr><th>Parameter</th><th>Description</th></tr></thead><tbody><tr><td><strong>Intent</strong></td><td>Represents the utterance that you used to test flow prediction. The AI-agent predicts the intention behind the input.</td></tr><tr><td><strong>Confidence</strong></td><td>A percentage (0 to 1) reflecting how accurate the predicted intent is. Higher values indicate greater certainty.<br> * Confidence is 1 when the AI-agent is absolutely sure about the intent.<br>* If the confidence is over 0.8, the prediction is considered accurate.</td></tr><tr><td><strong>Default Response</strong></td><td>The AI-agent&#x27;s response based on the input text.</td></tr><tr><td><strong>Entity</strong></td><td>Words or phrases representing nouns within the text. For example, in <strong>I want to buy a phone</strong>, Buy is the Intent and Phone is the Entity.</td></tr><tr><td><strong>Global Entity</strong></td><td>Entities (for example, dates, countries) recognized automatically by the platform.<br> * For <strong>Dates</strong>: DD-MM-YY, Today, Yesterday, Tomorrow, and more. <br> * For <strong>Countries</strong>: Japan, India, etc.</td></tr><tr><td><strong>Global Model</strong></td><td>Pre-trained phrases like Small Talk or Contexts, that help identify the intent.</td></tr></tbody></table>
<p><strong>Global model vs Global entity</strong></p>
<ul>
<li>
<p>Global Model identifies values based on phrases trained in Small talk and Context management, you can add multiple contexts based on your industry use-case.</p>
</li>
<li>
<p>Global entities identify values that are trained by the platform only for Dates and Locations. You cannot add/delete/modify the training.</p>
<p><img decoding="async" loading="lazy" src="https://imgur.com/ehXirsE.png" alt="" class="img_ev3q"></p>
</li>
</ul>
<p>To access global entities, use this snippet <code>{{{prediction.gloablEntities.0.text}}}</code>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="identify-the-emotion-via-verbose">Identify the emotion via Verbose<a href="#identify-the-emotion-via-verbose" class="hash-link" aria-label="Direct link to Identify the emotion via Verbose" title="Direct link to Identify the emotion via Verbose">​</a></h3>
<p>Enable <strong>Verbose</strong> to identify the emotion (sentiment) behind the text.</p>
<img src="https://i.imgur.com/U0iekzn.png" alt="drawing" width="60%">
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="test-your-bot-in-multiple-languages">Test your bot in multiple languages<a href="#test-your-bot-in-multiple-languages" class="hash-link" aria-label="Direct link to Test your bot in multiple languages" title="Direct link to Test your bot in multiple languages">​</a></h3>
<p>You can try out your AI-agent in various languages by just picking your preferred language from the dropdown menu.</p>
<img src="https://i.imgur.com/XJpwl4I.png" alt="drawing" width="60%">
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>To add languages to your AI-agent, check out the steps <a href="https://docs.yellow.ai/docs/platform_concepts/studio/build/localization#add-languages-to-your-bot" target="_blank" rel="noopener noreferrer">here</a>.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conversation">Conversation<a href="#conversation" class="hash-link" aria-label="Direct link to Conversation" title="Direct link to Conversation">​</a></h2>
<p>Here you can manage how conversations unfold, how messages are shown, and various elements related to the conversation.</p>
<p>You can oversee modifications through the following categories:</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="update-ai-agent-behaviour">Update AI-agent behaviour<a href="#update-ai-agent-behaviour" class="hash-link" aria-label="Direct link to Update AI-agent behaviour" title="Direct link to Update AI-agent behaviour">​</a></h3>
<p>This section consists of fields to control the behaviour of the conversation.</p>
<img src="https://i.imgur.com/lDz7NrX.png" alt="drawing" width="60%">
<table><thead><tr><th>Fields</th><th>Descriptions</th></tr></thead><tbody><tr><td><strong>Target language</strong></td><td>The default language in which the AI-agent will converse in before auto-suggestion or language change occurs. You can modify this if required.</td></tr><tr><td><strong>Translate quick reply responses</strong></td><td>Translate quick reply responses<br>(Does not work).</td></tr><tr><td><strong>Enable Hinglish</strong></td><td>Set <em>Yes</em> to allow the AI-agent to understand Hinglish (Hindi + English) utterances, tailored for Indian users.<br><img src="https://i.imgur.com/3Kt7IiD.png" width="300"></td></tr><tr><td><strong>Auto Detect Language</strong></td><td>Set <em>Yes</em> to enable the AI-agent to auto-identify the language a user types in and respond accordingly (if configured).<br><img src="https://i.imgur.com/p1xK8Sq.png" width="250"></td></tr><tr><td><strong>Enable Go Back/Go Home</strong></td><td>Shortcut for users to move to the previous step or go back home.<br><img src="https://i.imgur.com/fsJZA3R.png" width="300"></td></tr><tr><td><strong>Go back Aliases</strong></td><td>Configure keywords to trigger the <strong>Go back</strong> action and navigate to the previous conversation step.<br><img src="https://i.imgur.com/tt2P4FO.jpg" width="50%"></td></tr><tr><td><strong>Go home Aliases</strong></td><td>Specify keywords to trigger the <strong>Go home</strong> action and return to the beginning of the conversation.<br><img src="https://i.imgur.com/T1jOHPX.jpg" width="50%"></td></tr><tr><td><strong>Negation journey</strong></td><td>Collection of flows the AI-agent goes through when a user rejects an action.<br>For example:<br><br> * When the user inputs &quot;I want to talk to the manager&quot;, the AI-agent takes to the <em>Transfer to Agent</em> flow.<br>* If the user inputs &quot; I dont want to talk to the manager&quot;, the AI-agent takes the selected negation journey.<br><img src="https://i.imgur.com/VZalCux.png" width="50%"></td></tr></tbody></table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="intelligent-switching">Intelligent switching<a href="#intelligent-switching" class="hash-link" aria-label="Direct link to Intelligent switching" title="Direct link to Intelligent switching">​</a></h3>
<p>This section helps the AI-agent to switch the conversation based on user input.</p>
<p>For instance, consider a scenario where:</p>
<ul>
<li>AI-agent asks: &quot;Choose the type of account,&quot; offering options like Savings account or Fixed deposit.</li>
<li>User responds: &quot;Can you explain the difference between Savings account and Fixed deposit?&quot;</li>
</ul>
<p>With intelligent switching, the AI-agent would answer the user&#x27;s query and then smoothly transition back to the previous flow, prompting the user to &quot;Select a type of account&quot; again.</p>
<img src="https://i.imgur.com/Ix9CTWR.png" alt="drawing" width="80%">
<table><thead><tr><th>Fields</th><th>Descriptions</th></tr></thead><tbody><tr><td><strong>Enable</strong></td><td>Select <strong>Yes</strong> from the drop-down list to activate Intelligent Switching.</td></tr><tr><td><strong>Sticky Journeys</strong></td><td>Identify complex flows as <strong>sticky</strong> to minimize user interruption from the expected flow.<br>         When interruptions occur, a customizable sticky journey prompt encourages users to stay on that path. <br> If chosen, the current journey continues; if not, an alternative flow is suggested in a follow-up message.</td></tr><tr><td><strong>Prompt for sticky journeys</strong></td><td>Define the message to be displayed when a <strong>Sticky Journey</strong> is selected. This encourages users to complete the current flow.<br><img src="https://i.imgur.com/K8qsb52.png" width="50%"></td></tr><tr><td><strong>Followup message</strong></td><td>Redirects the conversation back to the desired flow like &quot;Do you want to continue where you left off?&quot; or &quot;What would you like to do next?&quot;<br> <img src="https://i.imgur.com/FpRIio0.png" width="50%"></td></tr></tbody></table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-validation-settings">Step validation settings<a href="#step-validation-settings" class="hash-link" aria-label="Direct link to Step validation settings" title="Direct link to Step validation settings">​</a></h3>
<p>This helps you configure the settings related to validating the steps involved in the AI-agent conversation. In simple words, you can configure this to validate prompts.</p>
<img src="https://i.imgur.com/7mMh5Nz.png" width="70%">
<p>When platform quick replies are configured, they appear in WhatsApp as a list of items in text.</p>
<p>For example -
What do you want to do next?</p>
<ol>
<li>Check order status</li>
<li>Receive notification</li>
<li>Go back to Main Menu</li>
</ol>
<p>You can customise this format <strong>Whatsapp Quick reply index</strong> and <strong>Structure prefix</strong> fields.</p>
<table><thead><tr><th>Fields</th><th>Descriptions</th></tr></thead><tbody><tr><td><strong>Whatsapp Quick reply index</strong></td><td>Choose the preferred indexing: <em>Numbers</em> (default), <em>Alphabets</em>, or <em>Emojis</em> (numerical emojis).</td></tr><tr><td><strong>Structure prefix</strong></td><td>Display the complete prefix with formatting. Default is <code>{{index}}</code>, as shown above.<br><br>                   For instance, <strong><em>Type</em> <code>{{index}}</code> for</strong> will show <strong>Type 1 for Gate Mechanical</strong>, <strong>Type 2 for AE &amp; JE Mechanical</strong> which simplifies selection of options. <br> <img decoding="async" loading="lazy" src="https://i.imgur.com/yQtdhUD.png" alt="" class="img_ev3q"></td></tr><tr><td><strong>Show prompt again</strong></td><td>Enable to show the original prompt after a validation failure message with <em>Yes</em> from the dropdown.<br><br>      For instance, when an incorrect phone number is entered, the prompt can be displayed again.</td></tr><tr><td><strong>Enable limit on retries</strong></td><td>Enable the default retry limit (3 times) with <strong>Yes</strong>.</td></tr><tr><td><strong>Error message</strong></td><td>Set the error message for validation failure.<br><br> For example: Hey, you&#x27;ve reached the maximum retry limit. <br> <img decoding="async" loading="lazy" src="https://i.imgur.com/8l46UFv.png" alt="" class="img_ev3q"></td></tr><tr><td><strong>Unknown message</strong></td><td>Define the message for system inability to validate the prompt response.                           <br><br> For example: <strong>It seems I can&#x27;t understand your input, could you rephrase it?</strong></td></tr></tbody></table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="autoskipping-settings">Autoskipping settings<a href="#autoskipping-settings" class="hash-link" aria-label="Direct link to Autoskipping settings" title="Direct link to Autoskipping settings">​</a></h3>
<p>Enable this option to allow the AI-agent to inform the user that it already has the information that is being provided.</p>
<p>You can skip a prompt using entitity or variable if the value already exists. This helps avoid asking users the same question multiple times depicting the memory of your AI-agent.</p>
<img src="https://i.imgur.com/Hvu2ioK.png" width="65%">
<table><thead><tr><th>Fields</th><th>Descriptions</th></tr></thead><tbody><tr><td><strong>Acknowledgment</strong></td><td>Activate this option for the AI-agent to receive user acknowledgment to automatically skip the upcoming flow.</td></tr><tr><td><strong>Acknowledgment prompt</strong></td><td>Type the message to be displayed to the user when the AI-agent suggests auto-skipping the upcoming step in the flow.</td></tr><tr><td><strong>Invalid prompt</strong></td><td>This message will appear when the user enters an invalid prompt.</td></tr><tr><td><strong>Confirm button label</strong></td><td>The label on the confirm button which users click to confirm that the option can be skipped.</td></tr><tr><td><strong>Modify button label</strong></td><td>The label on the edit button when users choose to modify their selection.</td></tr></tbody></table>
<p>To configure autoskip at node level, click <a href="https://docs.yellow.ai/docs/platform_concepts/studio/build/nodes/prompt-nodes#autoskip" target="_blank" rel="noopener noreferrer">here</a>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="global-autocomplete">Global autocomplete<a href="#global-autocomplete" class="hash-link" aria-label="Direct link to Global autocomplete" title="Direct link to Global autocomplete">​</a></h3>
<p>In the <strong>What do you want to show for autocomplete</strong> option, you can select the choice that the AI-agent will use to autocomplete the user&#x27;s input.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="nlu">NLU<a href="#nlu" class="hash-link" aria-label="Direct link to NLU" title="Direct link to NLU">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="prediction">Prediction<a href="#prediction" class="hash-link" aria-label="Direct link to Prediction" title="Direct link to Prediction">​</a></h3>
<p>Our machine learning system matches user input sentences to specific intents with confidence scores between 0 and 1. You can adjust the desired confidence level. The default confident score on the platform is 0.85.</p>
<img src="https://i.imgur.com/Ik9ozKr.png" width="65%">
<table><thead><tr><th>Fields</th><th>Descriptions</th></tr></thead><tbody><tr><td><strong>Min Confidence</strong></td><td>Set the minimum value below which the AI-agent won&#x27;t trigger an intent. For instance, if set to 0.85, the AI-agent responds only when the intent&#x27;s confidence level for the input is over 85%. <img src="https://i.imgur.com/7DM473O.png" width="300"><strong>Use case:</strong><br><br> When a user says <strong>Talk to your agent</strong> and <strong>Min Confidence</strong> is 0.85, the AI-agent responds correctly only if the intent predicted is <strong>Transfer Agent</strong> with a confidence of 1.<img src="https://i.imgur.com/k5bc5Tz.png" widht="60%"><br> However, if the user types <strong>Talk to tech support</strong>, the AI-agent won&#x27;t reply as the confidence for the predicted intent is uncertain. <img src="https://i.imgur.com/aok3dur.png" width="90%"></td></tr><tr><td><strong>Context Confidence</strong></td><td>Specify the minimum confidence score required for context accuracy.</td></tr><tr><td><strong>Secondary Model Confidence</strong></td><td>A global contextual model value. If the predicted value is below the threshold entered, the intent won&#x27;t trigger.</td></tr></tbody></table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="document-search-settings">Document search settings<a href="#document-search-settings" class="hash-link" aria-label="Direct link to Document search settings" title="Direct link to Document search settings">​</a></h3>
<img src="https://i.imgur.com/vaIpqm5.png" width="65%">
<table><thead><tr><th>Option</th><th>Description</th></tr></thead><tbody><tr><td>Document search threshold</td><td>To improve document search accuracy, adjust the threshold value between 0 and 1: <br>• <strong>Value set to 0</strong>: Irrelevant results might be shown. <br>• <strong>Value set to 1</strong>: More relevant matching results will be shown.<br> An ideal confidence level is between 0.6 and 0.8. You can increase or decrease this based on the document cognition search results for the uploaded documents.</td></tr><tr><td>Boost document rank by</td><td>Choose the preference by which the user query should match - Headers or Paragraph. This parameter can be used to boost the document ranks.<br><br>For example, if a document has a header with the user data and rest of content below it and Boost document rank by is enabled, this document will show up higher in ranks as the query users data matches the header in the document.</td></tr></tbody></table>
<p><img decoding="async" loading="lazy" src="https://i.imgur.com/hLQTC4N.png" alt="" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="multi-intent-settings">Multi Intent Settings<a href="#multi-intent-settings" class="hash-link" aria-label="Direct link to Multi Intent Settings" title="Direct link to Multi Intent Settings">​</a></h3>
<p>Enabling <strong>Multi-Intent</strong> allows the model to identify two intents in a single user message. For example, if this option is on and the user types <strong>Book a flight</strong> and <strong>reserve a hotel</strong> (assuming proper <a href="https://docs.yellow.ai/docs/platform_concepts/studio/train/intents#train-your-bot-with-intents" target="_blank" rel="noopener noreferrer">training to the AI-agent</a>, the model will detect both <strong>Book a flight</strong> and <strong>Reserve a hotel</strong> as intents.</p>
<p>After detecting the intents, the model will acknowledge this (via an Acknowledgment message) and ask the user which task they want to start with. The options will be provided as quick reply choices.</p>
<hr>
<p>Other options and the <strong>Go home</strong> option will also be suggested as quick replies, along with a follow-up message (similar to <strong>Intelligent Switching</strong>).</p>
<img src="https://i.imgur.com/CCIjO7s.png" width="55%">
<table><thead><tr><th>Fields</th><th>Descriptions</th></tr></thead><tbody><tr><td>Enable</td><td>Set <em>Yes</em> to enable multi-intent.</td></tr><tr><td>Acknowledgement question</td><td>The acknowledge message to display when multiple intents are detected. <br> Sample message: I understand, What would you like to do first?</td></tr><tr><td>Followup question</td><td>Question to ask in follow up to the previous question. <br> Sample message: Would you like to proceed?</td></tr></tbody></table>
<p><img decoding="async" loading="lazy" src="https://i.imgur.com/s4zM19K.png" alt="" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="add-constant-values">Add constant values<a href="#add-constant-values" class="hash-link" aria-label="Direct link to Add constant values" title="Direct link to Add constant values">​</a></h2>
<p>This section helps you add values that remain constant throughout the conversation. It can be a person&#x27;s name, a file name or any value that will not be modified as the conversation progresses.</p>
<p>Add constants by clicking the <strong>+Add Constants button</strong> and click <strong>Save</strong> to store those values in the database.</p>
<img src="https://i.imgur.com/ikUXSHT.png" width="55%">
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="voice">Voice<a href="#voice" class="hash-link" aria-label="Direct link to Voice" title="Direct link to Voice">​</a></h2>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>You can configure these settings only when IVR <strong>Channel</strong> is connected. Click <a href="https://docs.yellow.ai/docs/platform_concepts/channelConfiguration/Ivr" target="_blank" rel="noopener noreferrer">here</a> to learn how.</p></div></div>
<p>The voice global options that are configured will be applicable for all the nodes and journeys for the AI-agent. Node-level options can be configured for each node specifically. Whenever a global option and also node level option are defined, for that specific node, the node level option will be given more priority. For example,</p>
<ul>
<li><strong>Global level</strong>: You can select an STT/TTS engine globally so that you don’t have to configure it for each node.</li>
<li><strong>Node level</strong>: You can configure different “recording max duration” for different nodes i.e. 10 seconds for address and 5 seconds for name node.</li>
</ul>
<p>Voice bot global options/settings are classified depending upon different uses as below:</p>
<ol>
<li><strong>Telephony</strong>: For settings related to telephony like call forwarding, calling line identity, etc.</li>
<li><strong>Recording</strong>: Recording options such as beep sound after a question is asked.</li>
<li><strong>Speech to Text</strong>: You can customise a speech recognition software that enables the recognition and translation of spoken language into text.</li>
<li><strong>Text-to-Speech</strong>: You can customise the Text-to-Speech (TTS) capabilities to play back text in a spoken voice.</li>
<li><strong>Conversation</strong>: Yellow cloud provides additional conversational options to further customize and elevate the experience on the IVR channel.</li>
<li><strong>Others</strong>: Miscellaneous settings to handle invalid and blank user responses and fallbacks.</li>
</ol>
<p><img decoding="async" loading="lazy" src="https://i.imgur.com/I4cS4Nn.png" alt="" class="img_ev3q"></p>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_BuS1"><p>Most of the options can be configured globally.</p><p>If they are configured at the <a href="https://docs.yellow.ai/docs/platform_concepts/studio/build/nodes#32-configure-node-for-a-voice-bot" target="_blank" rel="noopener noreferrer">node level</a>, node level customisation takes priority over the global level settings.</p></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="telephony-related-voice-settings">Telephony related voice settings<a href="#telephony-related-voice-settings" class="hash-link" aria-label="Direct link to Telephony related voice settings" title="Direct link to Telephony related voice settings">​</a></h4>
<table><thead><tr><th>Fields</th><th>Description</th></tr></thead><tbody><tr><td><strong>Custom SIP header</strong></td><td>This can be used as an additional parameter that can be passed to an agent while transferring the call to an Agent to pass along AI-agent collected information. You can pass a key-value pair in JSON format which will get passed in the SIP header.</td></tr></tbody></table>
<blockquote>
<p>An example of the Custom SIP header:</p>
</blockquote>
<p><code>[{“key”:“User-to-User”, “value”:“name=david&amp;product=heater&amp;query=not turning off&amp;priority=high&amp;number=12345”}]</code></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="recording-related-voice-settings">Recording related voice settings<a href="#recording-related-voice-settings" class="hash-link" aria-label="Direct link to Recording related voice settings" title="Direct link to Recording related voice settings">​</a></h4>
<table><thead><tr><th>Fields</th><th>Description</th></tr></thead><tbody><tr><td><strong>Recording after call forward</strong></td><td>When this option is enabled the call will get recorded even after it has been transferred to an agent. This can be disabled for use cases with recording sensitive information.</td></tr><tr><td><strong>Enable recording beep</strong></td><td>When this is enabled, a beep sound will be played after the AI-agent asks a question giving an auditory response to the end-user to respond.</td></tr><tr><td><strong>Recording Action</strong></td><td>With the recording management options, you can select to pause/resume/stop recording depending upon different use-cases and conversations. By default, the recording is ON only. Also, in a call, once you STOP the recording (for recording sensitive dialogues), it can’t be resumed back.</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="stt-related-voice-settings">STT related voice settings<a href="#stt-related-voice-settings" class="hash-link" aria-label="Direct link to STT related voice settings" title="Direct link to STT related voice settings">​</a></h4>
<table><thead><tr><th>Fields</th><th>Description</th></tr></thead><tbody><tr><td><strong>STT engine</strong></td><td>Select an engine from the dropdown- Google/Microsoft.</td></tr><tr><td><strong>STT mode</strong></td><td>Select mode from the dropdown. Microsoft provides &quot;Static&quot;, &quot;Streaming&quot; or &quot;Streaming Advanced&quot;. Google provides &quot;Static&quot;.</td></tr><tr><td><strong>STT language</strong></td><td>AI-agent Language(ISO code) can be selected from the dropdown. Default- English. Click <a href="https://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/language-support?tabs=stt-tts" target="_blank" rel="noopener noreferrer">Microsoft</a> or <a href="https://cloud.google.com/speech-to-text/docs/languages" target="_blank" rel="noopener noreferrer">Google</a> for more information on the languages)</td></tr><tr><td><strong>Recording max duration</strong></td><td>This value is the Max duration for which the AI-agent will wait after asking a question (in any step) even while the user is speaking. For example, after asking “Which city are you from?” and the recording duration value is “5&quot; - the AI-agent records only 5 seconds of user response. This option is necessary to avoid consuming unwanted information and to stay with the conversational flow. If the user mistakenly replies with long paragraphs when a question is asked or if the user&#x27;s response is getting shadowed with constant background noises, the AI-agent must not process those long inputs. Hence, with this configuration, the AI-agent only takes the necessary response and can quickly process the user response.</td></tr><tr><td><strong>Recording silence duration</strong></td><td>Apart from recording max duration which caps the maximum time of user response, to further make the conversation lively and realistic, another parameter is configuring the expected silence duration. Recording silence duration is the max SILENCE duration for which the AI-agent will wait after asking a question (in any step) for the user to respond. While setting the silence duration, please note that it is applicable to the whole duration of user response, meaning, the silence at any point of user response be it at - (a) initial thinking/processing time OR (b) in between pauses of user response shouldn’t be greater than configured silence duration.  Applicable with Microsoft and Google with STT mode set as STATIC.</td></tr><tr><td><strong>Initial silence duration</strong></td><td>To provide more customization on the silence duration parameter, “streaming” and “streaming-advanced” STT modes (of Microsoft STT engine) allow to specifically configure the maximum acceptable silence duration before the user starts speaking.  For example, the acceptable initial silence duration for the application number question could be higher (~3/4 seconds) but in the case of a quick conversational binary question, it could be configured to 1 second.</td></tr><tr><td><strong>Final silence duration</strong></td><td>Similar to the initial silence duration, the final silence duration is indicative of the maximum duration of pause that the AI-agent will wait for once the user has started speaking. For example, for binary/one-word questions like yes/no we could set the final silence duration to ~0.5/1.0 seconds and for address-like fields where taking a pause is intrinsic in conversation, we can set the final silence duration to ~1.5/2.5 seconds.</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="tts-related-voice-settings">TTS related voice settings<a href="#tts-related-voice-settings" class="hash-link" aria-label="Direct link to TTS related voice settings" title="Direct link to TTS related voice settings">​</a></h4>
<table><thead><tr><th>Fields</th><th>Description</th></tr></thead><tbody><tr><td><strong>TTS engine</strong></td><td>Select the engines from the dropdown- Microsoft Azure, Google Wavenet, Amazon Polly.</td></tr><tr><td><strong>Text type</strong></td><td>Select Text/SSML from the dropdown.</td></tr><tr><td><strong>TTS language</strong></td><td>AI-agent Language(ISO code) can be selected from the dropdown.</td></tr><tr><td><strong>Pitch</strong></td><td>Pitch value can be any decimal value depending on the base of voice required, 0 is ideal. You can add this for Microsoft if text_type = &quot;text&quot; and for Google for text_type = &quot;text&quot; and &quot;SSML&quot;.</td></tr><tr><td><strong>Voice ID</strong></td><td>Type the characters of voice ID. You can add this for Microsoft if text_type = &quot;text&quot; and for Google if text_type = &quot;text&quot; and &quot;SSML&quot;.</td></tr><tr><td><strong>TTS Speed</strong></td><td>This value defines how fast the AI-agent must converse. This value can be 0.9 - 1.5 for the AI-agent to soundly humanly. You can add this for Microsoft if text_type = &quot;text&quot; and for Google if text_type = &quot;text&quot; and &quot;SSML&quot;.</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="conversation-related-voice-settings">Conversation related voice settings<a href="#conversation-related-voice-settings" class="hash-link" aria-label="Direct link to Conversation related voice settings" title="Direct link to Conversation related voice settings">​</a></h4>
<table><thead><tr><th>Fields</th><th>Description</th></tr></thead><tbody><tr><td><strong>Enable acknowledgement message</strong></td><td>When this is enabled, an acknowledgement kind message (“hmmm” OR “okay”) could be spoken in the conversation immediately. This is a small custom feature built to bring more human touch to the conversation.</td></tr><tr><td><strong>Acknowledgement message</strong></td><td>Enter a text/SSML message depending upon the configuration under the Text Type field. Keep it short for a better user experience.  . Ex: &quot;Do you want to confirm?&quot;</td></tr><tr><td><strong>Boost phrases</strong></td><td>Some user responses can be confusing for the AI-agent to understand. Region-specific words, new Genz lingos, internet terminologies, trending phrases, and abbreviations are trained especially so that the AI-agent understands the exact intention. For example, COVID is a new term that has been used frequently, the phrase COVID must be boosted, otherwise, it gets translated to kovind/ go we/ co-wid etc. Ex: you should add the phrases that you expect from the user response like, &lt; I want to take covid vaccine &gt;</td></tr></tbody></table>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="other-voice-settings">Other voice settings<a href="#other-voice-settings" class="hash-link" aria-label="Direct link to Other voice settings" title="Direct link to Other voice settings">​</a></h4>
<table><thead><tr><th>Fields</th><th>Description</th></tr></thead><tbody><tr><td><strong>Repeat limit</strong></td><td>In cases of a blank user response to the question, this is the number of times a repeat message should be played. For example, if the value is 3, the AI-agent asks the user to respond 3 times before following the fallback Configuration.</td></tr><tr><td><strong>Repeat fallback flow</strong></td><td>Select the conversation fallback to be configured in cases of blank user response even after repeated tries. Currently only support - <strong>disconnect</strong> and <strong>agent transfer</strong> as the fallback options.</td></tr><tr><td><strong>Disconnect message</strong></td><td>Message to be played before disconnecting the call as a part of fallback. For example, &quot;Have a nice day. Bye!&quot;</td></tr></tbody></table></div></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/platform_concepts/studio/train/add-contextual-response"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Contextual Responses</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/platform_concepts/studio/train/orchllm"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Orchestrator LLM</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#access-tools" class="table-of-contents__link toc-highlight">Access tools</a></li><li><a href="#test-your-bot" class="table-of-contents__link toc-highlight">Test your bot</a><ul><li><a href="#response-parameters" class="table-of-contents__link toc-highlight">Response parameters</a></li><li><a href="#identify-the-emotion-via-verbose" class="table-of-contents__link toc-highlight">Identify the emotion via Verbose</a></li><li><a href="#test-your-bot-in-multiple-languages" class="table-of-contents__link toc-highlight">Test your bot in multiple languages</a></li></ul></li><li><a href="#conversation" class="table-of-contents__link toc-highlight">Conversation</a><ul><li><a href="#update-ai-agent-behaviour" class="table-of-contents__link toc-highlight">Update AI-agent behaviour</a></li><li><a href="#intelligent-switching" class="table-of-contents__link toc-highlight">Intelligent switching</a></li><li><a href="#step-validation-settings" class="table-of-contents__link toc-highlight">Step validation settings</a></li><li><a href="#autoskipping-settings" class="table-of-contents__link toc-highlight">Autoskipping settings</a></li><li><a href="#global-autocomplete" class="table-of-contents__link toc-highlight">Global autocomplete</a></li></ul></li><li><a href="#nlu" class="table-of-contents__link toc-highlight">NLU</a><ul><li><a href="#prediction" class="table-of-contents__link toc-highlight">Prediction</a></li><li><a href="#document-search-settings" class="table-of-contents__link toc-highlight">Document search settings</a></li><li><a href="#multi-intent-settings" class="table-of-contents__link toc-highlight">Multi Intent Settings</a></li></ul></li><li><a href="#add-constant-values" class="table-of-contents__link toc-highlight">Add constant values</a></li><li><a href="#voice" class="table-of-contents__link toc-highlight">Voice</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer"><div class="container container-fluid"></div></footer></div>
</body>
</html>