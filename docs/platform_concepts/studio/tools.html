<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-platform_concepts/studio/tools">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.2.0">
<title data-rh="true">Tools and settings | yellow.ai</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" property="og:image" content="https://docs.yellow.ai/img/og_img.png"><meta data-rh="true" name="twitter:image" content="https://docs.yellow.ai/img/og_img.png"><meta data-rh="true" property="og:url" content="https://docs.yellow.ai/docs/platform_concepts/studio/tools"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="twitter:card" content="summary"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Tools and settings | yellow.ai"><meta data-rh="true" name="description" content="You can find advanced settings in the tools section, that will help you to finely adjust your AI-agent&#x27;s performance. You can calibrate language understanding through NLU, configure conversational behavior, add constant values that do not change in any conversations, and prepare for upcoming Voice capabilities. These tools collectively elevate your AI-agent&#x27;s performance and user engagement."><meta data-rh="true" property="og:description" content="You can find advanced settings in the tools section, that will help you to finely adjust your AI-agent&#x27;s performance. You can calibrate language understanding through NLU, configure conversational behavior, add constant values that do not change in any conversations, and prepare for upcoming Voice capabilities. These tools collectively elevate your AI-agent&#x27;s performance and user engagement."><link data-rh="true" rel="icon" href="/img/favicon.svg"><link data-rh="true" rel="canonical" href="https://docs.yellow.ai/docs/platform_concepts/studio/tools"><link data-rh="true" rel="alternate" href="https://docs.yellow.ai/docs/platform_concepts/studio/tools" hreflang="en"><link data-rh="true" rel="alternate" href="https://docs.yellow.ai/docs/platform_concepts/studio/tools" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://LWOORM11IH-dsn.algolia.net" crossorigin="anonymous"><link rel="preconnect" href="https://www.google-analytics.com">
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","G-NDQJKXFGTV","auto"),ga("send","pageview")</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-NDQJKXFGTV"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-NDQJKXFGTV",{anonymize_ip:!0})</script>




<link rel="search" type="application/opensearchdescription+xml" title="yellow.ai" href="/opensearch.xml">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/remixicon@2.5.0/fonts/remixicon.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Roboto&family=Source+Sans+Pro&display=swap">
<script src="/js/FeedbackFooter.js"></script>
<script src="/js/bot.js"></script><link rel="stylesheet" href="/assets/css/styles.d40f7a86.css">
<link rel="preload" href="/assets/js/runtime~main.941c831f.js" as="script">
<link rel="preload" href="/assets/js/main.b455cc35.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" target="_self" href="/"><div class="navbar__logo"><img src="/img/Yai-logo-yellow.svg" alt="yellow.ai" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/Yai-logo-yellow.svg" alt="yellow.ai" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate"></b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/platform_concepts/getting-started">Help Docs</a><a class="navbar__item navbar__link" href="/docs/cookbooks/getting_started">Use Case Guides</a><a class="navbar__item navbar__link" href="/api">API Reference</a><a class="navbar__item navbar__link" href="/docs/updates/overview">What&#x27;s New</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/docs/tutorials/basics">Videos</a><a href="https://community.yellow.ai" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Community</a><a href="https://cloud.yellow.ai/auth/signup?utm_source=SupportDocs&amp;utm_medium=doc_navbar&amp;utm_campaign=docs_april_23" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link free-signup">Try for free</a><div class="searchBox_ZlJk"><div><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebar_njMd"><nav class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/platform_concepts/getting-started">Get started with yellow.ai</a><button aria-label="Toggle the collapsible sidebar category &#x27;Get started with yellow.ai&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/docs/platform_concepts/studio/overview">Automation</a><button aria-label="Toggle the collapsible sidebar category &#x27;Automation&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/platform_concepts/studio/build/create-your-bot">Create your AI agent</a><button aria-label="Toggle the collapsible sidebar category &#x27;Create your AI agent&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/platform_concepts/studio/build/Flows/flows-overview">AI agent building tools</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/platform_concepts/studio/build/additionalsettings">AI-agent Conversation settings</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/docs/platform_concepts/studio/train/intents">Training AI agent data </a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/platform_concepts/studio/train/intents">Intents</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/platform_concepts/studio/train/entities">Entities</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/platform_concepts/studio/train/add-faqs">FAQ AI-agents</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/platform_concepts/studio/train/what-is-document-cognition">Documents</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/platform_concepts/studio/train/synonyms">Synonyms</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/platform_concepts/studio/train/smalltalk">Small talk</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/platform_concepts/studio/train/add-contextual-response">Contextual Responses</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/platform_concepts/studio/tools">Tools &amp; settings</a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/platform_concepts/studio/train/orchllm">Orchestrator LLM</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/docs/platform_concepts/studio/test-and-publish-bot/bot-logs">Test and publish AI agent</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/platform_concepts/studio/studio-faqs">Automation FAQs</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/platform_concepts/studio/LLM-central-configuration">LLM configuration</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/cookbooks/studio/debug-logs">Debug issues using logs</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/platform_concepts/studio/kb/overview">Knowledge hub</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/platform_concepts/emailAutomation">Email automation</a><button aria-label="Toggle the collapsible sidebar category &#x27;Email automation&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/platform_concepts/inbox">Inbox</a><button aria-label="Toggle the collapsible sidebar category &#x27;Inbox&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/platform_concepts/engagement/cdp/overview">User 360</a><button aria-label="Toggle the collapsible sidebar category &#x27;User 360&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/platform_concepts/engagement/engage">Engage</a><button aria-label="Toggle the collapsible sidebar category &#x27;Engage&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/platform_concepts/analyze/analyseintro">Analyze</a><button aria-label="Toggle the collapsible sidebar category &#x27;Analyze&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/platform_concepts/growth/introductiontoinsights">Insights</a><button aria-label="Toggle the collapsible sidebar category &#x27;Insights&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/platform_concepts/channelConfiguration/overview">Channels</a><button aria-label="Toggle the collapsible sidebar category &#x27;Channels&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/platform_concepts/appConfiguration/overview">Integrations</a><button aria-label="Toggle the collapsible sidebar category &#x27;Integrations&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/cookbooks/voice-as-channel/vbintro">AI Voice bot builder</a><button aria-label="Toggle the collapsible sidebar category &#x27;AI Voice bot builder&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/platform_concepts/yellowaisearch/yellow-search-feature">Yellow.ai&#x27;s smart search</a><button aria-label="Toggle the collapsible sidebar category &#x27;Yellow.ai&#x27;s smart search&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/docs/platform_concepts/mobile/inbox/android">Mobile SDK</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/platform_concepts/aicopilot">Help Center</a></li></ul></nav></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_OVgt"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/platform_concepts/studio/overview"><span itemprop="name">Automation</span></a><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Training AI agent data </span><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Tools &amp; settings</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Tools and settings</h1></header><p>You can find advanced settings in the tools section, that will help you to finely adjust your AI-agent&#x27;s performance. You can calibrate language understanding through NLU, configure conversational behavior, add constant values that do not change in any conversations, and prepare for upcoming Voice capabilities. These tools collectively elevate your AI-agent&#x27;s performance and user engagement.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="access-tools">Access tools<a class="hash-link" href="#access-tools" title="Direct link to heading">​</a></h2><p>To access the tools section:</p><ol><li><p>Go to <strong>Automation</strong> &gt; <strong>Train</strong> &gt; <strong>Intents</strong> &gt; <strong>Tools</strong></p><p><img loading="lazy" src="https://imgur.com/e4CgoyZ.png" class="img_ev3q"></p></li></ol><p>The tools section consists of five segments:</p><img loading="lazy" src="https://i.imgur.com/YrLTZ16.png" alt="drawing" width="60%" class="img_ev3q"><table><thead><tr><th>Tool</th><th>Description</th></tr></thead><tbody><tr><td>Test your bot</td><td>Analyse user-input sentences.</td></tr><tr><td>Conversation</td><td>Tailor <strong>Conversation settings</strong>, such as <strong>Behavior</strong>, <strong>Intelligent switching</strong>, <strong>Step validation</strong>, and <strong>Auto skip settings</strong>.</td></tr><tr><td>NLU</td><td>Customize technical specifics based on training.</td></tr><tr><td>Constants</td><td>Incorporate constant values stored in the database, such as names or filenames, ensuring continuity throughout interactions.</td></tr><tr><td>Voice</td><td>Adjust settings linked to the <strong>Voice</strong> feature on our platform.</td></tr></tbody></table><h2 class="anchor anchorWithStickyNavbar_LWe7" id="test-your-bot">Test your bot<a class="hash-link" href="#test-your-bot" title="Direct link to heading">​</a></h2><p>This section helps you check whether the associated intent will be triggered or not. The AI-agent utilizes prediction to determine the intention behind the input and evaluates the accuracy of the prediction. It also identifies the AI-agent&#x27;s response based on the input text, including automatically recognized entities.</p><p>For instance, when you type an utterance in the &quot;What user says?&quot; section, you&#x27;ll see the corresponding response and its confidence level displayed along with the related flow.</p><img loading="lazy" src="https://i.imgur.com/F5rVJIF.png" alt="drawing" width="60%" class="img_ev3q"><h3 class="anchor anchorWithStickyNavbar_LWe7" id="response-parameters">Response parameters<a class="hash-link" href="#response-parameters" title="Direct link to heading">​</a></h3><p>The following is a comprehensive description of the parameters in the response received for the typed input.</p><table><thead><tr><th>Parameter</th><th>Description</th></tr></thead><tbody><tr><td><strong>Intent</strong></td><td>Represents the utterance that you used to test flow prediction. The AI-agent predicts the intention behind the input.</td></tr><tr><td><strong>Confidence</strong></td><td>A percentage (0 to 1) reflecting how accurate the predicted intent is. Higher values indicate greater certainty.<br> <em> Confidence is 1 when the AI-agent is absolutely sure about the intent.<br></em> If the confidence is over 0.8, the prediction is considered accurate.</td></tr><tr><td><strong>Default Response</strong></td><td>The AI-agent&#x27;s response based on the input text.</td></tr><tr><td><strong>Entity</strong></td><td>Words or phrases representing nouns within the text. For example, in <strong>I want to buy a phone</strong>, Buy is the Intent and Phone is the Entity.</td></tr><tr><td><strong>Global Entity</strong></td><td>Entities (for example, dates, countries) recognized automatically by the platform.<br> <em> For <strong>Dates</strong>: DD-MM-YY, Today, Yesterday, Tomorrow, and more. <br> </em> For <strong>Countries</strong>: Japan, India, etc.</td></tr><tr><td><strong>Global Model</strong></td><td>Pre-trained phrases like Small Talk or Contexts, that help identify the intent.</td></tr></tbody></table><p><strong>Global model vs Global entity</strong></p><ul><li><p>Global Model identifies values based on phrases trained in Small talk and Context management, you can add multiple contexts based on your industry use-case. </p></li><li><p>Global entities identify values that are trained by the platform only for Dates and Locations. You cannot add/delete/modify the training. </p><p> <img loading="lazy" src="https://imgur.com/ehXirsE.png" class="img_ev3q"></p></li></ul><p>To access global entities, use this snippet <code>{{{prediction.gloablEntities.0.text}}}</code>.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="identify-the-emotion-via-verbose">Identify the emotion via Verbose<a class="hash-link" href="#identify-the-emotion-via-verbose" title="Direct link to heading">​</a></h3><p>Enable <strong>Verbose</strong> to identify the emotion (sentiment) behind the text.</p><img loading="lazy" src="https://i.imgur.com/U0iekzn.png" alt="drawing" width="60%" class="img_ev3q"><h3 class="anchor anchorWithStickyNavbar_LWe7" id="test-your-bot-in-multiple-languages">Test your bot in multiple languages<a class="hash-link" href="#test-your-bot-in-multiple-languages" title="Direct link to heading">​</a></h3><p>You can try out your AI-agent in various languages by just picking your preferred language from the dropdown menu.</p><img loading="lazy" src="https://i.imgur.com/XJpwl4I.png" alt="drawing" width="60%" class="img_ev3q"><div class="theme-admonition theme-admonition-note alert alert--secondary admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_S0QG"><p>To add languages to your AI-agent, check out the steps <a href="https://docs.yellow.ai/docs/platform_concepts/studio/build/localization#add-languages-to-your-bot" target="_blank" rel="noopener noreferrer">here</a>.</p></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="conversation">Conversation<a class="hash-link" href="#conversation" title="Direct link to heading">​</a></h2><p>Here you can manage how conversations unfold, how messages are shown, and various elements related to the conversation.</p><p>You can oversee modifications through the following categories:</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="update-ai-agent-behaviour">Update AI-agent behaviour<a class="hash-link" href="#update-ai-agent-behaviour" title="Direct link to heading">​</a></h3><p>This section consists of fields to control the behaviour of the conversation.</p><img loading="lazy" src="https://i.imgur.com/lDz7NrX.png" alt="drawing" width="60%" class="img_ev3q"><table><thead><tr><th>Fields</th><th>Descriptions</th></tr></thead><tbody><tr><td><strong>Target language</strong></td><td>The default language in which the AI-agent will converse in before auto-suggestion or language change occurs. You can modify this if required.</td></tr><tr><td><strong>Translate quick reply responses</strong></td><td>Translate quick reply responses<br>(Does not work).</td></tr><tr><td><strong>Enable Hinglish</strong></td><td>Set <em>Yes</em> to allow the AI-agent to understand Hinglish (Hindi + English) utterances, tailored for Indian users.<br><img loading="lazy" src="https://i.imgur.com/3Kt7IiD.png" width="300" class="img_ev3q"></td></tr><tr><td><strong>Auto Detect Language</strong></td><td>Set <em>Yes</em> to enable the AI-agent to auto-identify the language a user types in and respond accordingly (if configured).<br><img loading="lazy" src="https://i.imgur.com/p1xK8Sq.png" width="250" class="img_ev3q"></td></tr><tr><td><strong>Enable Go Back/Go Home</strong></td><td>Shortcut for users to move to the previous step or go back home.<br><img loading="lazy" src="https://i.imgur.com/fsJZA3R.png" width="300" class="img_ev3q"></td></tr><tr><td><strong>Go back Aliases</strong></td><td>Configure keywords to trigger the <strong>Go back</strong> action and navigate to the previous conversation step.<br><img loading="lazy" src="https://i.imgur.com/tt2P4FO.jpg" width="50%" class="img_ev3q"></td></tr><tr><td><strong>Go home Aliases</strong></td><td>Specify keywords to trigger the <strong>Go home</strong> action and return to the beginning of the conversation.<br><img loading="lazy" src="https://i.imgur.com/T1jOHPX.jpg" width="50%" class="img_ev3q"></td></tr><tr><td><strong>Negation journey</strong></td><td>Collection of flows the AI-agent goes through when a user rejects an action.<br>For example:<br><br> <em> When the user inputs &quot;I want to talk to the manager&quot;, the AI-agent takes to the </em>Transfer to Agent<em> flow.<br></em> If the user inputs &quot; I dont want to talk to the manager&quot;, the AI-agent takes the selected negation journey.<br><img loading="lazy" src="https://i.imgur.com/VZalCux.png" width="50%" class="img_ev3q"></td></tr></tbody></table><h3 class="anchor anchorWithStickyNavbar_LWe7" id="intelligent-switching">Intelligent switching<a class="hash-link" href="#intelligent-switching" title="Direct link to heading">​</a></h3><p>This section helps the AI-agent to switch the conversation based on user input.</p><p>For instance, consider a scenario where:</p><ul><li>AI-agent asks: &quot;Choose the type of account,&quot; offering options like Savings account or Fixed deposit. </li><li>User responds: &quot;Can you explain the difference between Savings account and Fixed deposit?&quot; </li></ul><p>With intelligent switching, the AI-agent would answer the user&#x27;s query and then smoothly transition back to the previous flow, prompting the user to &quot;Select a type of account&quot; again. </p><img loading="lazy" src="https://i.imgur.com/Ix9CTWR.png" alt="drawing" width="80%" class="img_ev3q"><table><thead><tr><th>Fields</th><th>Descriptions</th></tr></thead><tbody><tr><td><strong>Enable</strong></td><td>Select <strong>Yes</strong> from the drop-down list to activate Intelligent Switching.</td></tr><tr><td><strong>Sticky Journeys</strong></td><td>Identify complex flows as <strong>sticky</strong> to minimize user interruption from the expected flow.<br>         When interruptions occur, a customizable sticky journey prompt encourages users to stay on that path. <br> If chosen, the current journey continues; if not, an alternative flow is suggested in a follow-up message.</td></tr><tr><td><strong>Prompt for sticky journeys</strong></td><td>Define the message to be displayed when a <strong>Sticky Journey</strong> is selected. This encourages users to complete the current flow.<br><img loading="lazy" src="https://i.imgur.com/K8qsb52.png" width="50%" class="img_ev3q"></td></tr><tr><td><strong>Followup message</strong></td><td>Redirects the conversation back to the desired flow like &quot;Do you want to continue where you left off?&quot; or &quot;What would you like to do next?&quot;<br> <img loading="lazy" src="https://i.imgur.com/FpRIio0.png" width="50%" class="img_ev3q"></td></tr></tbody></table><h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-validation-settings">Step validation settings<a class="hash-link" href="#step-validation-settings" title="Direct link to heading">​</a></h3><p>This helps you configure the settings related to validating the steps involved in the AI-agent conversation. In simple words, you can configure this to validate prompts.</p><img loading="lazy" src="https://i.imgur.com/7mMh5Nz.png" width="70%" class="img_ev3q"><p>When platform quick replies are configured, they appear in WhatsApp as a list of items in text. </p><p>For example -
What do you want to do next?</p><ol><li>Check order status</li><li>Receive notification</li><li>Go back to Main Menu   </li></ol><p>You can customise this format <strong>Whatsapp Quick reply index</strong> and <strong>Structure prefix</strong> fields.  </p><table><thead><tr><th>Fields</th><th>Descriptions</th></tr></thead><tbody><tr><td><strong>Whatsapp Quick reply index</strong></td><td>Choose the preferred indexing: <em>Numbers</em> (default), <em>Alphabets</em>, or <em>Emojis</em> (numerical emojis).</td></tr><tr><td><strong>Structure prefix</strong></td><td>Display the complete prefix with formatting. Default is {{index}}, as shown above.<br><br>                   For instance, <strong><em>Type</em> {{index}} for</strong> will show <strong>Type 1 for Gate Mechanical</strong>, <strong>Type 2 for AE &amp; JE Mechanical</strong> which simplifies selection of options. <br> <img loading="lazy" src="https://i.imgur.com/yQtdhUD.png" class="img_ev3q"></td></tr><tr><td><strong>Show prompt again</strong></td><td>Enable to show the original prompt after a validation failure message with <em>Yes</em> from the dropdown.<br><br>      For instance, when an incorrect phone number is entered, the prompt can be displayed again.</td></tr><tr><td><strong>Enable limit on retries</strong></td><td>Enable the default retry limit (3 times) with <strong>Yes</strong>.</td></tr><tr><td><strong>Error message</strong></td><td>Set the error message for validation failure.<br><br> For example: Hey, you&#x27;ve reached the maximum retry limit. <br> <img loading="lazy" src="https://i.imgur.com/8l46UFv.png" class="img_ev3q"></td></tr><tr><td><strong>Unknown message</strong></td><td>Define the message for system inability to validate the prompt response.                           <br><br> For example: <strong>It seems I can&#x27;t understand your input, could you rephrase it?</strong></td></tr></tbody></table><h3 class="anchor anchorWithStickyNavbar_LWe7" id="autoskipping-settings">Autoskipping settings<a class="hash-link" href="#autoskipping-settings" title="Direct link to heading">​</a></h3><p>Enable this option to allow the AI-agent to inform the user that it already has the information that is being provided.</p><p>You can skip a prompt using entitity or variable if the value already exists. This helps avoid asking users the same question multiple times depicting the memory of your AI-agent.  </p><img loading="lazy" src="https://i.imgur.com/Hvu2ioK.png" width="65%" class="img_ev3q"><table><thead><tr><th>Fields</th><th>Descriptions</th></tr></thead><tbody><tr><td><strong>Acknowledgment</strong></td><td>Activate this option for the AI-agent to receive user acknowledgment to automatically skip the upcoming flow.</td></tr><tr><td><strong>Acknowledgment prompt</strong></td><td>Type the message to be displayed to the user when the AI-agent suggests auto-skipping the upcoming step in the flow.</td></tr><tr><td><strong>Invalid prompt</strong></td><td>This message will appear when the user enters an invalid prompt.</td></tr><tr><td><strong>Confirm button label</strong></td><td>The label on the confirm button which users click to confirm that the option can be skipped.</td></tr><tr><td><strong>Modify button label</strong></td><td>The label on the edit button when users choose to modify their selection.</td></tr></tbody></table><p>To configure autoskip at node level, click <a href="https://docs.yellow.ai/docs/platform_concepts/studio/build/nodes/prompt-nodes#autoskip" target="_blank" rel="noopener noreferrer">here</a>.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="global-autocomplete">Global autocomplete<a class="hash-link" href="#global-autocomplete" title="Direct link to heading">​</a></h3><p>In the <strong>What do you want to show for autocomplete</strong> option, you can select the choice that the AI-agent will use to autocomplete the user&#x27;s input.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="nlu">NLU<a class="hash-link" href="#nlu" title="Direct link to heading">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="prediction">Prediction<a class="hash-link" href="#prediction" title="Direct link to heading">​</a></h3><p>Our machine learning system matches user input sentences to specific intents with confidence scores between 0 and 1. You can adjust the desired confidence level. The default confident score on the platform is 0.85.</p><img loading="lazy" src="https://i.imgur.com/Ik9ozKr.png" width="65%" class="img_ev3q"><table><thead><tr><th>Fields</th><th>Descriptions</th></tr></thead><tbody><tr><td><strong>Min Confidence</strong></td><td>Set the minimum value below which the AI-agent won&#x27;t trigger an intent. For instance, if set to 0.85, the AI-agent responds only when the intent&#x27;s confidence level for the input is over 85%. <img loading="lazy" src="https://i.imgur.com/7DM473O.png" width="300" class="img_ev3q"><strong>Use case:</strong><br><br> When a user says <strong>Talk to your agent</strong> and <strong>Min Confidence</strong> is 0.85, the AI-agent responds correctly only if the intent predicted is <strong>Transfer Agent</strong> with a confidence of 1.<img loading="lazy" src="https://i.imgur.com/k5bc5Tz.png" widht="60%" class="img_ev3q"><br> However, if the user types <strong>Talk to tech support</strong>, the AI-agent won&#x27;t reply as the confidence for the predicted intent is uncertain. <img loading="lazy" src="https://i.imgur.com/aok3dur.png" width="90%" class="img_ev3q"></td></tr><tr><td><strong>Context Confidence</strong></td><td>Specify the minimum confidence score required for context accuracy.</td></tr><tr><td><strong>Secondary Model Confidence</strong></td><td>A global contextual model value. If the predicted value is below the threshold entered, the intent won&#x27;t trigger.</td></tr></tbody></table><h3 class="anchor anchorWithStickyNavbar_LWe7" id="document-search-settings">Document search settings<a class="hash-link" href="#document-search-settings" title="Direct link to heading">​</a></h3><img loading="lazy" src="https://i.imgur.com/vaIpqm5.png" width="65%" class="img_ev3q"><table><thead><tr><th>Option</th><th>Description</th></tr></thead><tbody><tr><td>Document search threshold</td><td>To improve document search accuracy, adjust the threshold value between 0 and 1: <br>• <strong>Value set to 0</strong>: Irrelevant results might be shown. <br>• <strong>Value set to 1</strong>: More relevant matching results will be shown.<br> An ideal confidence level is between 0.6 and 0.8. You can increase or decrease this based on the document cognition search results for the uploaded documents.</td></tr><tr><td>Boost document rank by</td><td>Choose the preference by which the user query should match - Headers or Paragraph. This parameter can be used to boost the document ranks.<br><br>For example, if a document has a header with the user data and rest of content below it and Boost document rank by is enabled, this document will show up higher in ranks as the query users data matches the header in the document.</td></tr></tbody></table><p><img loading="lazy" src="https://i.imgur.com/hLQTC4N.png" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="multi-intent-settings">Multi Intent Settings<a class="hash-link" href="#multi-intent-settings" title="Direct link to heading">​</a></h3><p>Enabling <strong>Multi-Intent</strong> allows the model to identify two intents in a single user message. For example, if this option is on and the user types <strong>Book a flight</strong> and <strong>reserve a hotel</strong> (assuming proper <a href="https://docs.yellow.ai/docs/platform_concepts/studio/train/intents#train-your-bot-with-intents" target="_blank" rel="noopener noreferrer">training to the AI-agent</a>, the model will detect both <strong>Book a flight</strong> and <strong>Reserve a hotel</strong> as intents.</p><p>After detecting the intents, the model will acknowledge this (via an Acknowledgment message) and ask the user which task they want to start with. The options will be provided as quick reply choices.</p><hr><p>Other options and the <strong>Go home</strong> option will also be suggested as quick replies, along with a follow-up message (similar to <strong>Intelligent Switching</strong>).</p><img loading="lazy" src="https://i.imgur.com/CCIjO7s.png" width="55%" class="img_ev3q"><table><thead><tr><th>Fields</th><th>Descriptions</th></tr></thead><tbody><tr><td>Enable</td><td>Set <em>Yes</em> to enable multi-intent.</td></tr><tr><td>Acknowledgement question</td><td>The acknowledge message to display when multiple intents are detected. <br> Sample message: I understand, What would you like to do first?</td></tr><tr><td>Followup question</td><td>Question to ask in follow up to the previous question. <br> Sample message: Would you like to proceed?</td></tr></tbody></table><p><img loading="lazy" src="https://i.imgur.com/s4zM19K.png" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="add-constant-values">Add constant values<a class="hash-link" href="#add-constant-values" title="Direct link to heading">​</a></h2><p>This section helps you add values that remain constant throughout the conversation. It can be a person&#x27;s name, a file name or any value that will not be modified as the conversation progresses. </p><p>Add constants by clicking the <strong>+Add Constants button</strong> and click <strong>Save</strong> to store those values in the database.</p><img loading="lazy" src="https://i.imgur.com/ikUXSHT.png" width="55%" class="img_ev3q"><h2 class="anchor anchorWithStickyNavbar_LWe7" id="voice">Voice<a class="hash-link" href="#voice" title="Direct link to heading">​</a></h2><div class="theme-admonition theme-admonition-note alert alert--secondary admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_S0QG"><p>You can configure these settings only when IVR <strong>Channel</strong> is connected. Click <a href="https://docs.yellow.ai/docs/platform_concepts/channelConfiguration/Ivr" target="_blank" rel="noopener noreferrer">here</a> to learn how. </p></div></div><p>The voice global options that are configured will be applicable for all the nodes and journeys for the AI-agent. Node-level options can be configured for each node specifically. Whenever a global option and also node level option are defined, for that specific node, the node level option will be given more priority. For example,  </p><ul><li><strong>Global level</strong>: You can select an STT/TTS engine globally so that you don’t have to configure it for each node.</li><li><strong>Node level</strong>: You can configure different “recording max duration” for different nodes i.e. 10 seconds for address and 5 seconds for name node.</li></ul><p>Voice bot global options/settings are classified depending upon different uses as below:  </p><ol><li><strong>Telephony</strong>: For settings related to telephony like call forwarding, calling line identity, etc.</li><li><strong>Recording</strong>: Recording options such as beep sound after a question is asked.</li><li><strong>Speech to Text</strong>: You can customise a speech recognition software that enables the recognition and translation of spoken language into text.</li><li><strong>Text-to-Speech</strong>: You can customise the Text-to-Speech (TTS) capabilities to play back text in a spoken voice.</li><li><strong>Conversation</strong>: Yellow cloud provides additional conversational options to further customize and elevate the experience on the IVR channel.</li><li><strong>Others</strong>: Miscellaneous settings to handle invalid and blank user responses and fallbacks.</li></ol><p><img loading="lazy" src="https://i.imgur.com/I4cS4Nn.png" class="img_ev3q"></p><div class="theme-admonition theme-admonition-note alert alert--secondary admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_S0QG"><p>Most of the options can be configured globally.</p><p>If they are configured at the <a href="https://docs.yellow.ai/docs/platform_concepts/studio/build/nodes#32-configure-node-for-a-voice-bot" target="_blank" rel="noopener noreferrer">node level</a>, node level customisation takes priority over the global level settings.</p></div></div><h4 class="anchor anchorWithStickyNavbar_LWe7" id="telephony-related-voice-settings">Telephony related voice settings<a class="hash-link" href="#telephony-related-voice-settings" title="Direct link to heading">​</a></h4><table><thead><tr><th>Fields</th><th>Description</th></tr></thead><tbody><tr><td><strong>Custom SIP header</strong></td><td>This can be used as an additional parameter that can be passed to an agent while transferring the call to an Agent to pass along AI-agent collected information. You can pass a key-value pair in JSON format which will get passed in the SIP header.</td></tr></tbody></table><blockquote><p>An example of the Custom SIP header:    </p></blockquote><p><code>[{“key”:“User-to-User”, “value”:“name=david&amp;product=heater&amp;query=not turning off&amp;priority=high&amp;number=12345”}]</code> </p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="recording-related-voice-settings">Recording related voice settings<a class="hash-link" href="#recording-related-voice-settings" title="Direct link to heading">​</a></h4><table><thead><tr><th>Fields</th><th>Description</th></tr></thead><tbody><tr><td><strong>Recording after call forward</strong></td><td>When this option is enabled the call will get recorded even after it has been transferred to an agent. This can be disabled for use cases with recording sensitive information.</td></tr><tr><td><strong>Enable recording beep</strong></td><td>When this is enabled, a beep sound will be played after the AI-agent asks a question giving an auditory response to the end-user to respond.</td></tr><tr><td><strong>Recording Action</strong></td><td>With the recording management options, you can select to pause/resume/stop recording depending upon different use-cases and conversations. By default, the recording is ON only. Also, in a call, once you STOP the recording (for recording sensitive dialogues), it can’t be resumed back.</td></tr></tbody></table><h4 class="anchor anchorWithStickyNavbar_LWe7" id="stt-related-voice-settings">STT related voice settings<a class="hash-link" href="#stt-related-voice-settings" title="Direct link to heading">​</a></h4><table><thead><tr><th>Fields</th><th>Description</th></tr></thead><tbody><tr><td><strong>STT engine</strong></td><td>Select an engine from the dropdown- Google/Microsoft.</td></tr><tr><td><strong>STT mode</strong></td><td>Select mode from the dropdown. Microsoft provides &quot;Static&quot;, &quot;Streaming&quot; or &quot;Streaming Advanced&quot;. Google provides &quot;Static&quot;.</td></tr><tr><td><strong>STT language</strong></td><td>AI-agent Language(ISO code) can be selected from the dropdown. Default- English. Click <a href="https://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/language-support?tabs=stt-tts" target="_blank" rel="noopener noreferrer">Microsoft</a> or <a href="https://cloud.google.com/speech-to-text/docs/languages" target="_blank" rel="noopener noreferrer">Google</a> for more information on the languages)</td></tr><tr><td><strong>Recording max duration</strong></td><td>This value is the Max duration for which the AI-agent will wait after asking a question (in any step) even while the user is speaking. For example, after asking “Which city are you from?” and the recording duration value is “5&quot; - the AI-agent records only 5 seconds of user response. This option is necessary to avoid consuming unwanted information and to stay with the conversational flow. If the user mistakenly replies with long paragraphs when a question is asked or if the user&#x27;s response is getting shadowed with constant background noises, the AI-agent must not process those long inputs. Hence, with this configuration, the AI-agent only takes the necessary response and can quickly process the user response.</td></tr><tr><td><strong>Recording silence duration</strong></td><td>Apart from recording max duration which caps the maximum time of user response, to further make the conversation lively and realistic, another parameter is configuring the expected silence duration. Recording silence duration is the max SILENCE duration for which the AI-agent will wait after asking a question (in any step) for the user to respond. While setting the silence duration, please note that it is applicable to the whole duration of user response, meaning, the silence at any point of user response be it at - (a) initial thinking/processing time OR (b) in between pauses of user response shouldn’t be greater than configured silence duration.  Applicable with Microsoft and Google with STT mode set as STATIC.</td></tr><tr><td><strong>Initial silence duration</strong></td><td>To provide more customization on the silence duration parameter, “streaming” and “streaming-advanced” STT modes (of Microsoft STT engine) allow to specifically configure the maximum acceptable silence duration before the user starts speaking.  For example, the acceptable initial silence duration for the application number question could be higher (~3/4 seconds) but in the case of a quick conversational binary question, it could be configured to 1 second.</td></tr><tr><td><strong>Final silence duration</strong></td><td>Similar to the initial silence duration, the final silence duration is indicative of the maximum duration of pause that the AI-agent will wait for once the user has started speaking. For example, for binary/one-word questions like yes/no we could set the final silence duration to ~0.5/1.0 seconds and for address-like fields where taking a pause is intrinsic in conversation, we can set the final silence duration to ~1.5/2.5 seconds.</td></tr></tbody></table><h4 class="anchor anchorWithStickyNavbar_LWe7" id="tts-related-voice-settings">TTS related voice settings<a class="hash-link" href="#tts-related-voice-settings" title="Direct link to heading">​</a></h4><table><thead><tr><th>Fields</th><th>Description</th></tr></thead><tbody><tr><td><strong>TTS engine</strong></td><td>Select the engines from the dropdown- Microsoft Azure, Google Wavenet, Amazon Polly.</td></tr><tr><td><strong>Text type</strong></td><td>Select Text/SSML from the dropdown.</td></tr><tr><td><strong>TTS language</strong></td><td>AI-agent Language(ISO code) can be selected from the dropdown.</td></tr><tr><td><strong>Pitch</strong></td><td>Pitch value can be any decimal value depending on the base of voice required, 0 is ideal. You can add this for Microsoft if text_type = &quot;text&quot; and for Google for text_type = &quot;text&quot; and &quot;SSML&quot;.</td></tr><tr><td><strong>Voice ID</strong></td><td>Type the characters of voice ID. You can add this for Microsoft if text_type = &quot;text&quot; and for Google if text_type = &quot;text&quot; and &quot;SSML&quot;.</td></tr><tr><td><strong>TTS Speed</strong></td><td>This value defines how fast the AI-agent must converse. This value can be 0.9 - 1.5 for the AI-agent to soundly humanly. You can add this for Microsoft if text_type = &quot;text&quot; and for Google if text_type = &quot;text&quot; and &quot;SSML&quot;.</td></tr></tbody></table><h4 class="anchor anchorWithStickyNavbar_LWe7" id="conversation-related-voice-settings">Conversation related voice settings<a class="hash-link" href="#conversation-related-voice-settings" title="Direct link to heading">​</a></h4><table><thead><tr><th>Fields</th><th>Description</th></tr></thead><tbody><tr><td><strong>Enable acknowledgement message</strong></td><td>When this is enabled, an acknowledgement kind message (“hmmm” OR “okay”) could be spoken in the conversation immediately. This is a small custom feature built to bring more human touch to the conversation.</td></tr><tr><td><strong>Acknowledgement message</strong></td><td>Enter a text/SSML message depending upon the configuration under the Text Type field. Keep it short for a better user experience.  . Ex: &quot;Do you want to confirm?&quot;</td></tr><tr><td><strong>Boost phrases</strong></td><td>Some user responses can be confusing for the AI-agent to understand. Region-specific words, new Genz lingos, internet terminologies, trending phrases, and abbreviations are trained especially so that the AI-agent understands the exact intention. For example, COVID is a new term that has been used frequently, the phrase COVID must be boosted, otherwise, it gets translated to kovind/ go we/ co-wid etc. Ex: you should add the phrases that you expect from the user response like, &lt; I want to take covid vaccine &gt;</td></tr></tbody></table><h4 class="anchor anchorWithStickyNavbar_LWe7" id="other-voice-settings">Other voice settings<a class="hash-link" href="#other-voice-settings" title="Direct link to heading">​</a></h4><table><thead><tr><th>Fields</th><th>Description</th></tr></thead><tbody><tr><td><strong>Repeat limit</strong></td><td>In cases of a blank user response to the question, this is the number of times a repeat message should be played. For example, if the value is 3, the AI-agent asks the user to respond 3 times before following the fallback Configuration.</td></tr><tr><td><strong>Repeat fallback flow</strong></td><td>Select the conversation fallback to be configured in cases of blank user response even after repeated tries. Currently only support - <strong>disconnect</strong> and <strong>agent transfer</strong> as the fallback options.</td></tr><tr><td><strong>Disconnect message</strong></td><td>Message to be played before disconnecting the call as a part of fallback. For example, &quot;Have a nice day. Bye!&quot;</td></tr></tbody></table></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/platform_concepts/studio/train/add-contextual-response"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Contextual Responses</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/platform_concepts/studio/train/orchllm"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Orchestrator LLM</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#access-tools" class="table-of-contents__link toc-highlight">Access tools</a></li><li><a href="#test-your-bot" class="table-of-contents__link toc-highlight">Test your bot</a><ul><li><a href="#response-parameters" class="table-of-contents__link toc-highlight">Response parameters</a></li><li><a href="#identify-the-emotion-via-verbose" class="table-of-contents__link toc-highlight">Identify the emotion via Verbose</a></li><li><a href="#test-your-bot-in-multiple-languages" class="table-of-contents__link toc-highlight">Test your bot in multiple languages</a></li></ul></li><li><a href="#conversation" class="table-of-contents__link toc-highlight">Conversation</a><ul><li><a href="#update-ai-agent-behaviour" class="table-of-contents__link toc-highlight">Update AI-agent behaviour</a></li><li><a href="#intelligent-switching" class="table-of-contents__link toc-highlight">Intelligent switching</a></li><li><a href="#step-validation-settings" class="table-of-contents__link toc-highlight">Step validation settings</a></li><li><a href="#autoskipping-settings" class="table-of-contents__link toc-highlight">Autoskipping settings</a></li><li><a href="#global-autocomplete" class="table-of-contents__link toc-highlight">Global autocomplete</a></li></ul></li><li><a href="#nlu" class="table-of-contents__link toc-highlight">NLU</a><ul><li><a href="#prediction" class="table-of-contents__link toc-highlight">Prediction</a></li><li><a href="#document-search-settings" class="table-of-contents__link toc-highlight">Document search settings</a></li><li><a href="#multi-intent-settings" class="table-of-contents__link toc-highlight">Multi Intent Settings</a></li></ul></li><li><a href="#add-constant-values" class="table-of-contents__link toc-highlight">Add constant values</a></li><li><a href="#voice" class="table-of-contents__link toc-highlight">Voice</a></li></ul></div></div></div></div></main></div></div><footer class="footer"><div class="container container-fluid"></div></footer></div>
<script src="/assets/js/runtime~main.941c831f.js"></script>
<script src="/assets/js/main.b455cc35.js"></script>
</body>
</html>