"use strict";(self.webpackChunkbenthos=self.webpackChunkbenthos||[]).push([[63126],{603905:function(e,t,n){n.d(t,{Zo:function(){return u},kt:function(){return h}});var r=n(667294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var l=r.createContext({}),c=function(e){var t=r.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},u=function(e){var t=c(e.components);return r.createElement(l.Provider,{value:t},e.children)},d="mdxType",f={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},p=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,o=e.originalType,l=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),d=c(n),p=a,h=d["".concat(l,".").concat(p)]||d[p]||f[p]||o;return n?r.createElement(h,i(i({ref:t},u),{},{components:n})):r.createElement(h,i({ref:t},u))}));function h(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=n.length,i=new Array(o);i[0]=p;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[d]="string"==typeof e?e:a,i[1]=s;for(var c=2;c<o;c++)i[c]=n[c];return r.createElement.apply(null,i)}return r.createElement.apply(null,n)}p.displayName="MDXCreateElement"},213115:function(e,t,n){n.r(t),n.d(t,{assets:function(){return u},contentTitle:function(){return l},default:function(){return p},frontMatter:function(){return s},metadata:function(){return c},toc:function(){return d}});var r=n(487462),a=n(263366),o=(n(667294),n(603905)),i=["components"],s={title:"Voice FAQs",sidebar_label:"Voice FAQs"},l=void 0,c={unversionedId:"cookbooks/voice-as-channel/voicefaqs",id:"cookbooks/voice-as-channel/voicefaqs",title:"Voice FAQs",description:"What are the languages supported for Voice Bot?",source:"@site/docs/cookbooks/voice-as-channel/voicefaqs.md",sourceDirName:"cookbooks/voice-as-channel",slug:"/cookbooks/voice-as-channel/voicefaqs",permalink:"/docs/cookbooks/voice-as-channel/voicefaqs",draft:!1,tags:[],version:"current",frontMatter:{title:"Voice FAQs",sidebar_label:"Voice FAQs"},sidebar:"platform_concepts",previous:{title:"WebRTC for voice agents testing",permalink:"/docs/cookbooks/voice-as-channel/WebrtcTesting"},next:{title:"Yellow.ai Search",permalink:"/docs/platform_concepts/yellowaisearch/yellow-search-feature"}},u={},d=[],f={toc:d};function p(e){var t=e.components,n=(0,a.Z)(e,i);return(0,o.kt)("wrapper",(0,r.Z)({},f,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("details",null,(0,o.kt)("summary",null," What are the languages supported for Voice Bot? "),(0,o.kt)("div",null,(0,o.kt)("div",null," Language support depends on the STT/TTS engine selected. ",(0,o.kt)("a",{href:"https://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/language-support?tabs=stt"}," Languages supported in Microsoft engine. ")))),(0,o.kt)("details",null,(0,o.kt)("summary",null,"Can yellow voice agents support DTMF inputs?"),(0,o.kt)("div",null,(0,o.kt)("div",null," Yes, voice agents support both speech recognition and DTMF (keypad) inputs. ",(0,o.kt)("a",{href:"https://docs.yellow.ai/docs/cookbooks/voice-as-channel/usecases/dtmf"}," Learn more here. ")))),(0,o.kt)("details",null,(0,o.kt)("summary",null,"How will voice-agent work with third-party CRM?"),(0,o.kt)("div",null,(0,o.kt)("div",null," It can integrate with any CRM for picking up information or posting back updates as long as we have APIs available to configure. "))),(0,o.kt)("details",null,(0,o.kt)("summary",null,"How can the voice agent transfer contextual information (like name, number, etc) collect from the end user to the contact center as well?"),(0,o.kt)("div",null,(0,o.kt)("div",null," We can use SIP Header transfer or Tonetag transfer to pass extra information while doing the call transfer. "))),(0,o.kt)("details",null,(0,o.kt)("summary",null,"What are the STT engines provided for configuration?"),(0,o.kt)("div",null,(0,o.kt)("div",null," Currently we have native integrations with Microsoft and Google for our STT services."))),(0,o.kt)("details",null,(0,o.kt)("summary",null,"Can the agent be configured for regional languages?"),(0,o.kt)("div",null,(0,o.kt)("div",null," Yes, a voice agent (same as a chat agent) can be configured for multiple languages."))),(0,o.kt)("details",null,(0,o.kt)("summary",null,"How a voice agent can capture alphanumeric inputs accurately from user speech?"),(0,o.kt)("div",null,(0,o.kt)("div",null," Accuracy depends on many factors like the complexity of the input, background noise, etc. If the list of these characters is available (for example a list of Product IDs or an Order ID) we can train the voice agent on the same using boost phrases. "))),(0,o.kt)("details",null,(0,o.kt)("summary",null,"Can voice agent dynamically understand different languages and if required, switch the language on the fly?"),(0,o.kt)("div",null,(0,o.kt)("div",null," Yes, this can be done using the Auto-Language Detection feature. Currently, this is under Beta. ",(0,o.kt)("a",{href:"https://docs.yellow.ai/docs/cookbooks/voice-as-channel/usecases/languagedetection"}," Learn more here. "),"  "))),(0,o.kt)("details",null,(0,o.kt)("summary",null,"Why is the voice data different in the Insights and Engage dashboards?"),(0,o.kt)("div",null,"In Engage, there is a 2-5 minute window for checking the status of voice campaign calls. During this time, calls are queued in the voice queue. The status is then sent in the notification report. If the call status remains unchanged after this period, Engage considers the calls as failed to connect and moves the users to the next node. Hence, there might be a mismatch in the data displayed on the Insights vs. Engage dashboards/reports.")))}p.isMDXComponent=!0}}]);