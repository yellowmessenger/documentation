"use strict";(self.webpackChunkbenthos=self.webpackChunkbenthos||[]).push([[57957],{28453:(e,s,n)=>{n.d(s,{R:()=>o,x:()=>l});var t=n(96540);const i={},r=t.createContext(i);function o(e){const s=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(s):{...s,...e}},[s,e])}function l(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),t.createElement(r.Provider,{value:s},e.children)}},82813:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>c,contentTitle:()=>l,default:()=>h,frontMatter:()=>o,metadata:()=>t,toc:()=>a});const t=JSON.parse('{"id":"platform_concepts/AIAgent/automated-agent-testing","title":"Test your AI agent using AI-based Test suites","description":"Automated AI agent testing (Agentic testing) allows you to validate the functionality, performance, and accuracy of your AI agents built on the agentic platform without relying on manual testing.","source":"@site/docs/platform_concepts/AIAgent/automated-agent-testing.md","sourceDirName":"platform_concepts/AIAgent","slug":"/platform_concepts/AIAgent/automated-agent-testing","permalink":"/docs/platform_concepts/AIAgent/automated-agent-testing","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Test your AI agent using AI-based Test suites","sidebar_label":"Test suites"},"sidebar":"platform_concepts","previous":{"title":"Preview AI agent","permalink":"/docs/platform_concepts/AIAgent/manage-conversation"},"next":{"title":"AI Copilot","permalink":"/docs/platform_concepts/AICopilot/copilot"}}');var i=n(74848),r=n(28453);const o={title:"Test your AI agent using AI-based Test suites",sidebar_label:"Test suites"},l=void 0,c={},a=[{value:"Key capabilities of Agentic AI testing",id:"key-capabilities-of-agentic-ai-testing",level:3},{value:"Types of test cases",id:"types-of-test-cases",level:3},{value:"Test case settings",id:"test-case-settings",level:3},{value:"Reports",id:"reports",level:3},{value:"Performance metrics",id:"performance-metrics",level:4},{value:"Summary",id:"summary",level:4},{value:"Execute test case",id:"execute-test-case",level:2},{value:"Knowledge base",id:"knowledge-base",level:3},{value:"Configure Set criteria for Knowledge base",id:"configure-set-criteria-for-knowledge-base",level:4},{value:"Run a test case for Knowledge base",id:"run-a-test-case-for-knowledge-base",level:3},{value:"View Knowledge base report",id:"view-knowledge-base-report",level:3},{value:"Test Copilot saved session",id:"test-copilot-saved-session",level:2},{value:"Configure set criteria for Copilot saved session",id:"configure-set-criteria-for-copilot-saved-session",level:4},{value:"Run a test case for Copilot saved session",id:"run-a-test-case-for-copilot-saved-session",level:3},{value:"View report of Copilot saved session",id:"view-report-of-copilot-saved-session",level:3},{value:"Scenario based testing",id:"scenario-based-testing",level:3},{value:"Prerequisites",id:"prerequisites",level:4},{value:"Configure Set criteria for scenario-based test case",id:"configure-set-criteria-for-scenario-based-test-case",level:4},{value:"Run a test case for Scenarios",id:"run-a-test-case-for-scenarios",level:4},{value:"Test Report Overview",id:"test-report-overview",level:4},{value:"View Scenarios report",id:"view-scenarios-report",level:4}];function d(e){const s={a:"a",admonition:"admonition",br:"br",em:"em",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(s.p,{children:"Automated AI agent testing (Agentic testing) allows you to validate the functionality, performance, and accuracy of your AI agents built on the agentic platform without relying on manual testing."}),"\n",(0,i.jsx)(s.p,{children:"With Automated testing, you can:"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"Generate test cases from your Knowledge base"}),"\n",(0,i.jsx)(s.li,{children:"Replay saved Copilot sessions"}),"\n",(0,i.jsx)(s.li,{children:"Retest past user conversations"}),"\n",(0,i.jsx)(s.li,{children:"Simulate end-to-end flows with scenario-based testing"}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:"It helps bot developers, QA engineers, conversation designers, and product owners who need to validate AI agent performance with every change or deployment across different environments."}),"\n",(0,i.jsx)(s.p,{children:"Manual testing whether through preview windows or live sessions is time consuming. It requires creating test cases, checking each step, and revalidating after every change. Automated testing simplifies this by enabling you to create, run, and review test cases with ease, saving time and ensuring reliability."}),"\n",(0,i.jsx)(s.h3,{id:"key-capabilities-of-agentic-ai-testing",children:"Key capabilities of Agentic AI testing"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Test from multiple sources"}),": Generates QnAs (Test cases) from Knowledge Base articles, Copilot sessions, past conversations, or custom scenarios."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Smart response evaluation"}),": Use configurable thresholds for accuracy and empathy to validate if responses are relevant and context-aware."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Goal-based scenario simulation"}),": Simulate realistic conversations using user rules and intents to test how the AI agent performs in complex, end-to-end flows."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Cross-environment validation"}),": Run tests across environments\u2014like sandbox and production\u2014to detect issues before they impact users."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Automated regression checks"}),": Revalidates existing test cases to ensure that updates to prompts, workflows, or configurations do not break previously functioning interactions."]}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.strong,{children:"Limitations"})}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"Test cases can only be executed in lower-tier environments such as Sandbox or Development. Testing is not available in Production or Live environments."}),"\n",(0,i.jsx)(s.li,{children:"You can run up to 200 test cases in a single execution. Each test is evaluated based on configurable thresholds such as Accuracy and Empathy with optional support for custom evaluation rules."}),"\n"]}),"\n",(0,i.jsx)(s.h3,{id:"types-of-test-cases",children:"Types of test cases"}),"\n",(0,i.jsx)(s.p,{children:"Automated AI agent testing supports four test case types, each designed to validate different aspects of an agent's performance to ensure consistent behavior across updates and environments."}),"\n",(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:(0,i.jsx)(s.a,{href:"#knowledge-base",children:"Knowledge base test case"})}),": Knowledge Base (KB) test case helps you verify if the AI agent is responding accurately based on the documents uploaded in the Knowledge Base. It ensures the agent retrieves the correct information from those files when answering questions. This is especially useful when handling large volumes of content like PDFs, website links (URLs), or data from APIs."]}),"\n",(0,i.jsx)(s.p,{children:"In the KB test case section, you can view the list of documents uploaded to the Knowledge Base. For each document, a question and answer pair (FAQ) is generated. You can generate FAQs for up to 100 documents at a time. When you run the test, the AI agent is asked these questions to check whether it responds with the expected answers to validate that it understands and uses the document content correctly."}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:(0,i.jsx)(s.a,{href:"#test-copilot-saved-session",children:"Copilot saved session"})}),": Copilot saved session test case allows you to capture and save user-agent interactions during a conversation within the AI Copilot. These saved sessions are useful for testing and debugging purposes. When a session is saved, it records the complete conversation between the user and the AI agent, including prompts, responses, and conversation context."]}),"\n",(0,i.jsx)(s.p,{children:"Once a session is saved in the Copilot Saved Session test case, it can be tested to evaluate how the AI agent performs based on that specific conversation."}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:(0,i.jsx)(s.a,{href:"#scenario-based-testing",children:"Scenario-based testing"})}),": Scenario based testing simulates goal-driven user journeys, such as booking a ticket or raising a refund request. You can define user attributes like name, location, preferences, or intent to set up the context.  The AI agent then uses this context to generate up to 10 scenarios per agent using this information."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:"If the auto-generated scenarios do not cover specific cases you want to test, you can create custom scenarios. You provide key details, and the AI fills in the remaining conversation flow, which you can edit further to match your exact requirements. These scenarios help test how well the agent handles changing inputs, context management, and different types of queries."}),"\n",(0,i.jsx)(s.p,{children:"Testing works on a credit system with a daily limit of 2,000 credits. Credits can be used for Knowledge Base, Copilot sessions, and Scenario-based tests. Each Knowledge Base test case consumes 1 credit per test case, while each Copilot session and Scenario-based test case consumes 10 credits."}),"\n",(0,i.jsx)(s.h3,{id:"test-case-settings",children:"Test case settings"}),"\n",(0,i.jsxs)(s.p,{children:["Automated testing provides two modes ",(0,i.jsx)(s.strong,{children:"Evaluation"})," and ",(0,i.jsx)(s.strong,{children:"Simulation"})," to help you measure how well your AI agent is performing."]}),"\n",(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.strong,{children:"Evaluation"})}),"\n",(0,i.jsx)(s.p,{children:"Evaluation checks whether your AI agent is giving the right answers and responding in the right tone. Use this mode when you want to test if the AI agent is giving correct responses after making updates to your knowledge base, prompts, or workflows. You need to define two key metrics before running the tests:"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Accuracy"}),": Measures how correct and relevant the agent\u2019s response is to the user\u2019s query. ",(0,i.jsx)(s.strong,{children:"Suggested threshold"}),": 75 for optimal accuracy."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Empathy"}),": Measures the tone of the response whether it is polite, helpful, or formal based on your brand guidelines. ",(0,i.jsx)(s.strong,{children:"Suggested threshold"}),": 75 for optimal empathy."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Rules"}),": You can also define what rules need to be followed by agent while running a test case, such as:","\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"Avoid casual language or jokes"}),"\n",(0,i.jsx)(s.li,{children:"Use specific phrases or keywords"}),"\n",(0,i.jsx)(s.li,{children:"Follow a defined tone (example, professional or friendly)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.strong,{children:"How it works:"})}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"Set thresholds for both accuracy and empathy (example, 80% accuracy and 90% empathy)."}),"\n",(0,i.jsx)(s.li,{children:"If a response falls below either threshold, the test case is marked as failed."}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/seteval.png",alt:"image"})}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Simulation"}),(0,i.jsx)("br",{})]}),"\n",(0,i.jsx)(s.p,{children:"Simulation mode is used when you want to test how the AI agent handles more complex, realistic conversations. It is especially useful for testing full user journeys like booking a flight, troubleshooting a product, or gathering customer information where the agent needs to maintain context across multiple steps."}),"\n",(0,i.jsx)(s.p,{children:"In this mode, you test a user by setting up attributes such as Name, Location, Preferences, and Intent (what the user wants to do) by defining the rules. This helps test how well your agent performs in real-time scenarios where it needs to understand context and ask follow-up questions."}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/simulationset.png",alt:"image"})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(s.h3,{id:"reports",children:"Reports"}),"\n",(0,i.jsx)(s.p,{children:"After configuring Evaluation and Simulation settings for automated AI agent testing, you can run test cases to generate detailed reports."}),"\n",(0,i.jsx)(s.p,{children:"Each test case is marked as either Success (\u2714\ufe0f) or Failure (\u274c) based on whether it meets the predefined thresholds for key performance metrics."}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/reports.png",alt:""})}),"\n",(0,i.jsx)(s.h4,{id:"performance-metrics",children:"Performance metrics"}),"\n",(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Accuracy score"}),": Measures how well the agent understood the user's question and responded with a correct and relevant answer.","\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"High value"})," (example, 100%): Agent fully understood and correctly resolved the query."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Low value"})," (< threshold): Indicates misinterpretation or incorrect/missing information."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Empathy score"}),": Evaluates whether the response uses an appropriate tone, empathetic, professional, or friendly depending on your use case.","\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"High value"})," (example, 90%): The bot responded with a suitable tone."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Low value"}),": Response may sound robotic or indifferent."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Clear communication"}),": How clearly and concisely the agent conveyed its response.","\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"High value"})," (example, 95%): Well-structured, easy-to-understand replies."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Low value"}),": Confusing, verbose, or poorly formatted answers."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Hallucination"}),": Indicates if the agent generated made-up or incorrect information not present in the knowledge base.","\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"0% is ideal, showing no false content."}),"\n",(0,i.jsx)(s.li,{children:"Higher value (>0%): The agent introduced misleading or fabricated information."}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Follow-up handling"}),": Evaluates how well the agent managed ongoing conversations and retained context.","\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"100% indicates excellent context handling."}),"\n",(0,i.jsx)(s.li,{children:"Lower scores suggest poor continuity, requiring users to repeat themselves."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(s.h4,{id:"summary",children:"Summary"}),"\n",(0,i.jsx)(s.p,{children:"Provides a overview of the test case outcome and scores. It consist of three parts:"}),"\n",(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Reason"}),": Describes how the agent's response aligned with the user's intent and the expected answer. Example: The agent responded with accurate, policy-based information and maintained relevance to the query."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Strengths"}),": Highlights the positive aspects of the response. Examples include:","\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"Accurate answers"}),"\n",(0,i.jsx)(s.li,{children:"Helpful added context"}),"\n",(0,i.jsx)(s.li,{children:"Polite tone and further assistance offered"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Areas for improvement"}),": Suggests where the response could be optimized. For example:","\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"Make responses more concise"}),"\n",(0,i.jsx)(s.li,{children:"Avoid unnecessary repetition of policy details"}),"\n",(0,i.jsx)(s.li,{children:"Balance added context with clarity"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(s.h2,{id:"execute-test-case",children:"Execute test case"}),"\n",(0,i.jsx)(s.h3,{id:"knowledge-base",children:"Knowledge base"}),"\n",(0,i.jsx)(s.p,{children:"To test knowledge base, follow these steps:"}),"\n",(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Navigate to ",(0,i.jsx)(s.strong,{children:"Automation"})," > ",(0,i.jsx)(s.strong,{children:"Test suites"}),"."]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/testsuite.png",alt:""})}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Select ",(0,i.jsx)(s.strong,{children:"Knowledge base"})," > click ",(0,i.jsx)(s.strong,{children:"+ Add document"}),"."]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/kbdoc.png",alt:"image"})}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"This will navigate you to the Kownledge base module."}),"\n"]}),"\n",(0,i.jsxs)(s.ol,{start:"4",children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Click ",(0,i.jsx)(s.strong,{children:"Add file"}),"."]}),"\n",(0,i.jsx)("img",{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/addfile.png",alt:"drawing",width:"90%"}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Click ",(0,i.jsx)(s.strong,{children:"Upload files"}),"."]}),"\n",(0,i.jsx)("img",{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/uploadfileskb.png",alt:"drawing",width:"70%"}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Select the file type that you want to upload and click ",(0,i.jsx)(s.strong,{children:"Next"}),"."]}),"\n",(0,i.jsx)("img",{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/fileuplaodkb.png",alt:"drawing",width:"70%"}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Upload the file and click ",(0,i.jsx)(s.strong,{children:"Add document"}),"."]}),"\n",(0,i.jsx)("img",{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/uploadfileadd.png",alt:"drawing",width:"70%"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"The document will be uploaded successfully."}),"\n"]}),"\n",(0,i.jsxs)(s.ol,{start:"8",children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Go to ",(0,i.jsx)(s.strong,{children:"Test suites"})," and click ",(0,i.jsx)(s.strong,{children:"Generate QnA"}),"."]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/generatefaq.png",alt:""})}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"FAQs will be generated for each uploaded document. You can generate FAQs for up to 100 documents at once."}),"\n"]}),"\n",(0,i.jsx)(s.h4,{id:"configure-set-criteria-for-knowledge-base",children:"Configure Set criteria for Knowledge base"}),"\n",(0,i.jsx)(s.p,{children:"After generating the test cases, you need to configure set criteria to define how the test should be evaluated."}),"\n",(0,i.jsx)(s.p,{children:"To configure set criteria, follow these steps:"}),"\n",(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Click ",(0,i.jsx)(s.strong,{children:"Set criteria"}),"."]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/setcriteria.png",alt:""})}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Set the Evaluation rules and click ",(0,i.jsx)(s.strong,{children:"Save"}),"."]}),"\n",(0,i.jsxs)(s.p,{children:["i. ",(0,i.jsx)(s.strong,{children:"Accuracy"}),": Set the empathy level on the slider. This determines how the AI agent's responses match the expected behavior. ",(0,i.jsx)("br",{}),(0,i.jsx)(s.strong,{children:"Value"}),": 75 \u2013 This is the suggested setting for optimal empathy.\nii. ",(0,i.jsx)(s.strong,{children:"Empathy"}),": Set the empathy level on the slider. It ensures the AI responds in a friendly, human-like manner. ",(0,i.jsx)("br",{}),(0,i.jsx)(s.strong,{children:"Value"}),": 75 \u2013 This is the suggested setting for optimal empathy.\niii. ",(0,i.jsx)(s.strong,{children:"Rules"}),": Define rules that the AI agent should follow during test case evaluation.",(0,i.jsx)("br",{}),"Example"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"Your questions must be phrased differently and varied each time to make it human-like. Each step should have actionable questions."}),"\n",(0,i.jsx)(s.li,{children:"If the user expresses anger or frustration immediately skip to cancellation."}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/seteval.png",alt:"image"})}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Set Simulation rules"}),": Add the rules to guide how the AI simulates user interactions during testing."]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"If the user provides incomplete information, simulate a natural follow-up question instead of re-asking the original question."}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"Always rephrase questions in a human-like manner to avoid repetition and mimic natural conversation patterns."}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/simulationset.png",alt:"image"})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(s.h3,{id:"run-a-test-case-for-knowledge-base",children:"Run a test case for Knowledge base"}),"\n",(0,i.jsx)(s.p,{children:"To run a test case, follow these steps:"}),"\n",(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"Go to the list of generated Knowledge Base test cases. Use the checkboxes to select one or more test cases you want to execute."}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/selcheckbox.png",alt:"image"})}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Click ",(0,i.jsx)(s.strong,{children:"Run test cases"})," button at the top."]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/selectrun.png",alt:""})}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Enter a ",(0,i.jsx)(s.strong,{children:"Execution name"})," and click ",(0,i.jsx)(s.strong,{children:"Run"}),". Note that, by default execution name will be displayed based on date and time."]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/nametestcase.png",alt:"image"})}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Click ",(0,i.jsx)(s.strong,{children:"Check reports"})," to view the results of the test case executions."]}),"\n",(0,i.jsx)("img",{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/check-report.png",alt:"drawing",width:"50%"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["In the ",(0,i.jsx)(s.strong,{children:"Report"})," section, you can view the status of each test case along with details like the accuracy score, empathy score, and whether the AI response meets your configured rules."]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/reportview.png",alt:"image"})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(s.h3,{id:"view-knowledge-base-report",children:"View Knowledge base report"}),"\n",(0,i.jsx)(s.p,{children:"You can view the detailed results of each test case and compare actual versus expected outcomes."}),"\n",(0,i.jsx)(s.p,{children:"To view report, follow these steps:"}),"\n",(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Click the ",(0,i.jsx)(s.strong,{children:"Execution name link"}),"."]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/testcasenamelink.png",alt:"image"})}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"Here, you can view the complete status of the report. This report contains Accuracy score, Empathy score, clear communication, Hallucination, and Follow-up handling."}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/analyzeconv1.png",alt:"image"})}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.ol,{start:"2",children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Click ",(0,i.jsx)(s.strong,{children:"Analyse conversation"})," to compare the expected FAQ and the agent\u2019s response during simulation."]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/comparision.png",alt:"image"})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(s.h2,{id:"test-copilot-saved-session",children:"Test Copilot saved session"}),"\n",(0,i.jsx)(s.p,{children:"You can test your AI agent using saved conversations from Copilot."}),"\n",(0,i.jsx)(s.p,{children:"To create and validate a Copilot saved session, follow these steps:"}),"\n",(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Navigate to ",(0,i.jsx)(s.strong,{children:"Automation"})," > ",(0,i.jsx)(s.strong,{children:"Test suites"}),"."]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/testsuite.png",alt:""})}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Click on ",(0,i.jsx)(s.strong,{children:"Copilot saved session"}),", then select ",(0,i.jsx)(s.strong,{children:"Go to Copilot"})," to begin creating the test case."]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/Gotocopilot.png",alt:""})}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"This will navigate you to the Copilot module."}),"\n"]}),"\n",(0,i.jsxs)(s.ol,{start:"3",children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["In Copilot, click ",(0,i.jsx)(s.strong,{children:"Begin with fresh conversation"})," to initiate a new test session."]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/begin.png",alt:""})}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Start the conversation and click ",(0,i.jsx)(s.strong,{children:"Save test case"})," icon to save the session."]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/savetestcase.png",alt:""})}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Enter a name for your test case and click ",(0,i.jsx)(s.strong,{children:"Save"}),"."]}),"\n",(0,i.jsx)("img",{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/savetescase.png",alt:"drawing",width:"60%"}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(s.admonition,{type:"note",children:(0,i.jsx)(s.p,{children:"You can save up to 10 pairs of conversation per testcase."})}),"\n",(0,i.jsxs)(s.ol,{start:"6",children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Click ",(0,i.jsx)(s.strong,{children:"Check testcase"})," to review your saved conversation. This will display the recorded session under the Copilot saved session tab."]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/checktestcase.png",alt:""})}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"The saved session will be displayed in the Copilot saved session tab."}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/flight.png",alt:""})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(s.h4,{id:"configure-set-criteria-for-copilot-saved-session",children:"Configure set criteria for Copilot saved session"}),"\n",(0,i.jsx)(s.p,{children:"After saving a test case, you need to configure set criteria to define how the Copilot should evaluate the session. This step helps ensure your AI agent behaves as expected."}),"\n",(0,i.jsx)(s.p,{children:"To configure set criteria, follow these steps:"}),"\n",(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["In the Copilot saved session tab, click on ",(0,i.jsx)(s.strong,{children:"Set criteria"})," for the test case you want to configure."]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/copilotcriteria.png",alt:""})}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Set the Evaluation rules and click ",(0,i.jsx)(s.strong,{children:"Save"}),"."]}),"\n",(0,i.jsxs)(s.p,{children:["i. ",(0,i.jsx)(s.strong,{children:"Accuracy"}),": Set the empathy level on the slider. This determines how the AI agent's responses match the expected behavior.",(0,i.jsx)("br",{}),(0,i.jsx)(s.strong,{children:"Value"}),": 75 \u2013 This is the suggested setting for optimal empathy.\nii. ",(0,i.jsx)(s.strong,{children:"Empathy"}),": Set the empathy level on the slider. This ensures the AI responds in a friendly, human-like tone.",(0,i.jsx)("br",{})," ",(0,i.jsx)(s.strong,{children:"Value"}),": 75 \u2013 This is the suggested setting for optimal empathy.",(0,i.jsx)("br",{}),"\niii. ",(0,i.jsx)(s.strong,{children:"Rules"}),": Define rules that the AI agent should follow during test case evaluation.",(0,i.jsx)("br",{})," Example:"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"Your questions must be phrased differently and varied each time to make it human-like."}),"\n",(0,i.jsx)(s.li,{children:"If the user expresses anger or frustration immediately skip to cancellation."}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/seteval.png",alt:"image"})}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Set Simulation rules"}),": Add the rules to guide how the AI simulates user interactions during testing."]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"If the user provides incomplete information, simulate a natural follow-up question instead of re-asking the original question."}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"Always rephrase questions in a human-like manner to avoid repetition and mimic natural conversation patterns."}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/simulationset.png",alt:"image"})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(s.h3,{id:"run-a-test-case-for-copilot-saved-session",children:"Run a test case for Copilot saved session"}),"\n",(0,i.jsx)(s.p,{children:"To run a test case for Copilot saved session, follow these steps:"}),"\n",(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"Go to the Copilot saved session tab. Use the checkboxes to select one or more test cases that you want to run."}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/selectcopilottestcase.png",alt:"image"})}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Click ",(0,i.jsx)(s.strong,{children:"Run test cases"})," button at the top."]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/copilotruntestcase.png",alt:""})}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"Enter an Execution name for the test run. By default, the name will be auto-filled based on the current date and time."}),"\n",(0,i.jsx)("img",{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/copilotsaved.png",alt:"drawing",width:"70%"}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Click ",(0,i.jsx)(s.strong,{children:"Run"})," to start the test execution."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Click ",(0,i.jsx)(s.strong,{children:"Check reports"})," to view the results of the test case execution."]}),"\n",(0,i.jsx)("img",{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/checkcopilot.png",alt:"drawing",width:"50%"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["In the ",(0,i.jsx)(s.strong,{children:"Report"})," section, you will see a summary of the test execution, including:","\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"Status (Passed/Failed)"}),"\n",(0,i.jsx)(s.li,{children:"Accuracy Score"}),"\n",(0,i.jsx)(s.li,{children:"Empathy Score"}),"\n",(0,i.jsxs)(s.li,{children:["Compliance with evaluation rules and simulation behavior\n",(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/copilottestcases.png",alt:"image"})]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(s.h3,{id:"view-report-of-copilot-saved-session",children:"View report of Copilot saved session"}),"\n",(0,i.jsx)(s.p,{children:"After running a Copilot saved session test, you can view detailed reports to evaluate how the AI agent performed compared to expected behavior."}),"\n",(0,i.jsx)(s.p,{children:"To view report, follow these steps:"}),"\n",(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Click the ",(0,i.jsx)(s.strong,{children:"Execution name link"}),"."]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/Copilotlink.png",alt:"image"})}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["Here, you can view the complete status of the report. This report provides a comprehensive overview of the AI agent's performance, including:","\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"Accuracy score"}),"\n",(0,i.jsx)(s.li,{children:"Empathy score"}),"\n",(0,i.jsx)(s.li,{children:"Clear communication"}),"\n",(0,i.jsx)(s.li,{children:"Hallucination"}),"\n",(0,i.jsxs)(s.li,{children:["Follow-up handling.\n",(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/analyzecopilot.png",alt:"image"})]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.ol,{start:"2",children:["\n",(0,i.jsxs)(s.li,{children:["Click on ",(0,i.jsx)(s.strong,{children:"Analyse conversation"})," to open a side-by-side view of:"]}),"\n"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"The Copilot conversation session (test input and expected flow)"}),"\n",(0,i.jsx)(s.li,{children:"The Simulated agent response (what actually happened during the test)"}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:"This allows you to compare expected vs actual behavior and ensures if the AI handled the conversation correctly."}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/copilotconversation.png",alt:"image"})}),"\n",(0,i.jsx)(s.h3,{id:"scenario-based-testing",children:"Scenario based testing"}),"\n",(0,i.jsx)(s.h4,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["You need to ",(0,i.jsx)(s.a,{href:"https://docs.yellow.ai/docs/platform_concepts/AIAgent/agent#create-an-agent",children:"create an agent"})," before starting scenario-based testing."]}),"\n",(0,i.jsxs)(s.li,{children:["Test scenarios can only be generated if your agent has configured start trigger or prompt. If your agent is created without these configurations, the ",(0,i.jsx)(s.strong,{children:"Generate"})," button will be disabled."]}),"\n"]}),"\n",(0,i.jsx)("center",{children:(0,i.jsx)("img",{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/disablegenerate.png",alt:"drawing",width:"40%"})}),"\n",(0,i.jsx)(s.p,{children:"To test a scenario, follow these steps:"}),"\n",(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Navigate to ",(0,i.jsx)(s.strong,{children:"Automation"})," > ",(0,i.jsx)(s.strong,{children:"Test suites"}),"."]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/testsuite.png",alt:""})}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Click on ",(0,i.jsx)(s.strong,{children:"Scenarios"})," > Test cases > ",(0,i.jsx)(s.strong,{children:"Generate"})," to create a list of test cases."]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/scenario-generate.png",alt:""})}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"A maximum of 10 scenarios will be generated per agent."}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/scenarios10.png",alt:""})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(s.h4,{id:"configure-set-criteria-for-scenario-based-test-case",children:"Configure Set criteria for scenario-based test case"}),"\n",(0,i.jsxs)(s.p,{children:["After generating test case, you need to configure ",(0,i.jsx)(s.em,{children:"Set criteria"}),"."]}),"\n",(0,i.jsx)(s.p,{children:"To configure set criteria, follow these steps:"}),"\n",(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["In the ",(0,i.jsx)(s.strong,{children:"Scenarios"})," tab, select the testcases and click on ",(0,i.jsx)(s.strong,{children:"Set criteria"})," for the test case you want to configure."]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/scenariocriteria.png",alt:""})}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Set the Evaluation rules and click ",(0,i.jsx)(s.strong,{children:"Save"}),"."]}),"\n",(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Accuracy"}),": Set the empathy level on the slider. This determines how the AI agent's responses match the expected behavior.",(0,i.jsx)("br",{}),(0,i.jsx)(s.strong,{children:"Value"}),": 75 \u2013 This is the suggested setting for optimal empathy."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Empathy"}),": Set the empathy level on the slider. This ensures the AI responds in a friendly, human-like tone.",(0,i.jsx)("br",{})," ",(0,i.jsx)(s.strong,{children:"Value"}),": 75 \u2013 This is the suggested setting for optimal empathy."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Rules"}),": Define rules that the AI agent should follow during test case evaluation. ",(0,i.jsx)("br",{}),(0,i.jsx)(s.strong,{children:"Example:"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsx)(s.li,{children:"Your questions must be phrased differently and varied each time to make it human-like."}),"\n",(0,i.jsxs)(s.li,{children:["If the user expresses anger or frustration immediately skip to cancellation.\n",(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/seteval.png",alt:"image"})]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Set Simulation rules"}),": Add the rules to guide how the AI simulates user interactions during testing."]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"If the user provides incomplete information, simulate a natural follow-up question instead of re-asking the original question."}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"Always rephrase questions in a human-like manner to avoid repetition and mimic natural conversation patterns."}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/simulationset.png",alt:"image"})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(s.h4,{id:"run-a-test-case-for-scenarios",children:"Run a test case for Scenarios"}),"\n",(0,i.jsx)(s.p,{children:"To run a test case for scenario, follow these steps:"}),"\n",(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Go to the ",(0,i.jsx)(s.strong,{children:"Scenarios"})," tab. Use the checkboxes to select one or more test cases that you want to run and click *",(0,i.jsx)(s.em,{children:"Run test cases"}),"."]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/scenarioruncase.png",alt:"image"})}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"Enter an execution name"})," for the test run. By default, the name will be auto-filled based on the current date and time."]}),"\n",(0,i.jsx)("img",{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/scenariorun.png",alt:"drawing",width:"70%"}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Click ",(0,i.jsx)(s.strong,{children:"Run"})," to start the test execution."]}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Click ",(0,i.jsx)(s.strong,{children:"Check reports"})," to view the results of the test case execution."]}),"\n",(0,i.jsx)("img",{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/scenarioreport.png",alt:"drawing",width:"50%"}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(s.h4,{id:"test-report-overview",children:"Test Report Overview"}),"\n",(0,i.jsxs)(s.p,{children:["In the ",(0,i.jsx)(s.strong,{children:"Report"})," section, you will see a summary of the test execution, which includes:"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Status (Passed/Failed):"})," Indicates whether the overall test scenario was successfully executed or not."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Success:"})," The number or percentage of test cases that met the expected outcome."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Failure:"})," The number or percentage of test cases that did not meet the expected outcome."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Accuracy:"})," Measures how closely the AI agent\u2019s responses matched the expected responses."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Empathy Score:"})," Evaluates the AI agent\u2019s ability to respond in a human-like, empathetic manner."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Clear Communication:"})," Assesses whether the AI agent\u2019s responses were easy to understand, concise, and free of ambiguity.",(0,i.jsx)(s.br,{}),"\n",(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/reportsview.png",alt:"image"})]}),"\n"]}),"\n",(0,i.jsx)(s.h4,{id:"view-scenarios-report",children:"View Scenarios report"}),"\n",(0,i.jsx)(s.p,{children:"After running a scenario test, you can access detailed reports to evaluate how the AI agent performed against the expected behavior."}),"\n",(0,i.jsx)(s.p,{children:"To view report, follow these steps:"}),"\n",(0,i.jsxs)(s.ol,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Click the ",(0,i.jsx)(s.strong,{children:"Execution name link"}),"."]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/execution-name-link.png",alt:"image"})}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"This opens the complete report, which provides a comprehensive overview of the AI agent\u2019s performance, including:"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Accuracy Score"})," \u2013 How closely the AI agent\u2019s responses matched the expected answers."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Empathy Score"})," \u2013 How effectively the AI agent demonstrated understanding and human-like empathy."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Clear Communication"})," \u2013 Whether responses were easy to understand, concise, and free of ambiguity."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Hallucination"})," \u2013 Instances where the AI agent generated incorrect or fabricated information."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Follow-up Handling"})," \u2013 How well the AI agent managed related or subsequent user queries."]}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/report-details-scenario.png",alt:"image"})}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(s.ol,{start:"2",children:["\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsxs)(s.p,{children:["Click on ",(0,i.jsx)(s.strong,{children:"Analyse conversation"})," to review detailed interaction-level analysis."]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/analyzescenario.png",alt:""})}),"\n"]}),"\n",(0,i.jsxs)(s.li,{children:["\n",(0,i.jsx)(s.p,{children:"In conversation analysis, the following key fields are available:"}),"\n",(0,i.jsxs)(s.ul,{children:["\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Scenario title"}),": The name of the specific test scenario that was executed. This helps you identify which scenario's conversation you are reviewing."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Scenario summary"}),": A short description of what the scenario is designed to test, giving quick context about the conversation's purpose."]}),"\n",(0,i.jsxs)(s.li,{children:[(0,i.jsx)(s.strong,{children:"Expected outcome"}),": The ideal or correct response the AI agent should provide during the test, based on the predefined scenario setup."]}),"\n"]}),"\n",(0,i.jsx)(s.p,{children:(0,i.jsx)(s.img,{src:"https://cdn.yellowmessenger.com/assets/yellow-docs/Analyze-conv.png",alt:""})}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:s}={...(0,r.R)(),...e.components};return s?(0,i.jsx)(s,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}}}]);