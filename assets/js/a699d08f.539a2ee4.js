"use strict";(self.webpackChunkbenthos=self.webpackChunkbenthos||[]).push([[17374],{27297:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>c,frontMatter:()=>i,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"cookbooks/voice-as-channel/conversationaldelays","title":"Understand delays in a conversation","description":"Delays are the time between the user response and the voice agent response.","source":"@site/docs/cookbooks/voice-as-channel/conversationaldelays.md","sourceDirName":"cookbooks/voice-as-channel","slug":"/cookbooks/voice-as-channel/conversationaldelays","permalink":"/docs/cookbooks/voice-as-channel/conversationaldelays","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Understand delays in a conversation","sidebar_label":"Understand conversational delays"},"sidebar":"platform_concepts","previous":{"title":"Set up outbound campaign","permalink":"/docs/cookbooks/voice-as-channel/OBcampaign/setupOBC"},"next":{"title":"Interruption handling","permalink":"/docs/cookbooks/voice-as-channel/usecases/interrupthandling"}}');var o=s(74848),r=s(28453);const i={title:"Understand delays in a conversation",sidebar_label:"Understand conversational delays"},a=void 0,l={},d=[{value:"1. Types of delays",id:"1-types-of-delays",level:2},{value:"2. Configure delays for different use cases",id:"2-configure-delays-for-different-use-cases",level:2},{value:"2.1 Configure for Yes/ No response",id:"21-configure-for-yes-no-response",level:3}];function h(e){const n={a:"a",admonition:"admonition",blockquote:"blockquote",h2:"h2",h3:"h3",hr:"hr",img:"img",li:"li",mdxAdmonitionTitle:"mdxAdmonitionTitle",ol:"ol",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.p,{children:'Delays are the time between the user response and the voice agent response.\nFor example, the user response is "is there any discount?", and the delay is the time that the voice agent takes to process a line and respond to it.'}),"\n",(0,o.jsx)(n.p,{children:"The objective of the Telephony and Yellow cloud platform is to reduce the conversational delay and make the conversation more human-like."}),"\n",(0,o.jsx)(n.p,{children:"Before understanding and configuring the voice agent for the best user experience in terms of minimising the conversation delay and still not cutting off the user mid-sentence, let's try to understand the way normal dialogue works."}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["When the response is a ",(0,o.jsx)(n.strong,{children:"Yes/No"})," value: This is supposed to be an instantaneous response and probably not a very long statement."]}),"\n",(0,o.jsxs)(n.li,{children:["When the response is an ",(0,o.jsx)(n.strong,{children:"address"}),": This consists of multiple pauses/gaps and a longer time to complete the whole response."]}),"\n"]}),"\n",(0,o.jsxs)(n.blockquote,{children:["\n",(0,o.jsx)(n.p,{children:"Ex: Door #1 < pause > Sector-D1 < pause > Kanpur Road < pause > Lucknow"}),"\n"]}),"\n",(0,o.jsxs)(n.ol,{start:"3",children:["\n",(0,o.jsxs)(n.li,{children:["When the response is a ",(0,o.jsx)(n.strong,{children:"phone number"}),": This will be a patterned delay and there will be a few pauses but the whole response is not very long."]}),"\n"]}),"\n",(0,o.jsxs)(n.blockquote,{children:["\n",(0,o.jsx)(n.p,{children:"Ex: 99-44-32-06-11 or +1-202-795-3213"}),"\n"]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"1-types-of-delays",children:"1. Types of delays"}),"\n",(0,o.jsx)(n.p,{children:"Once we have understood how normal dialogue dealy works, let's have a look at other kinds of delay that are introduced in the voice agent conversation.  After having a clear idea about the functioning of delays, we can better optimize the conversation around the same."}),"\n",(0,o.jsx)(n.p,{children:"Delay (or perceived delay to the user) is the amount of time it takes after the user completes the query/response and the agent voice out the next response."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{src:"https://i.imgur.com/ossdeuj.png",alt:""})}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"STT delay"}),": When the user has responded and the telephony platform has received the audio file. This delay is caused when the audio file is getting converted to the text file on the STT engine. This delay depends on the number of characters, simple name response will take lesser time to process than an address."]}),"\n"]}),"\n",(0,o.jsxs)(n.blockquote,{children:["\n",(0,o.jsx)(n.p,{children:'Ex: Audio-to-text conversation of "My name is Jake, what is my bank balance?"'}),"\n"]}),"\n",(0,o.jsx)(n.admonition,{type:"note",children:(0,o.jsxs)(n.p,{children:["The yellow cloud platform would have defined a range of duration for which the telephony platform accepts the response. For example, if the user is responding with a phone number we can ask the voice agent to only record it for 1 minute by setting the ",(0,o.jsx)(n.strong,{children:"Recording max duration"}),"."]})}),"\n",(0,o.jsxs)(n.ol,{start:"2",children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Telephony to yellow cloud platform"}),": The converted audio to text response will get transported from the telephony platform."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"NLP engine response time within cloud platform"}),": The text received on the yellow cloud platform will be sent to the NLP engine. Internally there will run a logical function where the software understands the user text response, finds a solution to continue the flow and generate a voice agent response."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Yellow to telephony cloud platform"}),": The text response generated by the NLU-yellow cloud platform will get transported to the telephony platform."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"TTS delay"}),": This delay occurs while the agent response text is getting converted to an audio format by the TTS engine so that it can be played as a response to the user."]}),"\n"]}),"\n",(0,o.jsxs)(n.admonition,{type:"info",children:[(0,o.jsx)(n.mdxAdmonitionTitle,{}),(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"TTS delay optimisation using cache memory"})}),(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Use case"}),': Assume you own an ominous that converses with 1000 users in a day and the conversation flow is mostly the same. Ex: First agent question will be "what is your name" and the next would be to inform the user - "we have introduced a 0% intro APR offer on both purchases and transfers".']}),(0,o.jsxs)(n.p,{children:["These repetitive messages or the small audio files remain the same throughout all the calls, hence the TTS delay that occurs while the NLP text response is getting converted to speech is optimised using ",(0,o.jsx)(n.strong,{children:"cache"}),". This skips the TTS delay and fetches the agent response from the cache database (present in the telephony platform)."]}),(0,o.jsx)(n.p,{children:"The audio files generated from the first few user conversations are stored in the database and reused for the other calls reducing the overall latency."})]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.h2,{id:"2-configure-delays-for-different-use-cases",children:"2. Configure delays for different use cases"}),"\n",(0,o.jsx)(n.p,{children:"Finally, after understanding the art of human dialogue and the system of voice agent, let us drill down on designing and configuring the agent in much better way.\nWhile understanding the system delays, there were 3 major parts to it:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.strong,{children:"STT"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.strong,{children:"Telephony-Cloud Communication"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.strong,{children:"TTS"})}),"\n"]}),"\n",(0,o.jsx)(n.admonition,{type:"note",children:(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Telephony-Cloud"})," stacks are very tightly integrated with each other and with a very reliable and fast NLP engine the whole delay for this section is negligible.\n",(0,o.jsx)(n.strong,{children:"TTS delay"})," is already very well optimized by using the caching mechanism explained above."]})}),"\n",(0,o.jsx)(n.p,{children:"Clever configuration lies is on how we optimize the STT delay. Let's understand that process below:"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Understanding STT detection"})}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Use-case"}),': The agent asks the user "Are you sure you want to place this order?" and the user responds with Yes/No.']}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Initial delay"}),": This delay occurs when the user hears the agent's response and takes time to process it before replying."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Information delay"}),": The time taken for the user to speak the complete response."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Pauses"}),": Pauses taken in between each of the words are considered a delay. Pause for a Yes/No answer will be nill and there will be multiple pauses while recording an address."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Final dealy"}),": After the user has spoken the response, the duration of time the agent waits to understand that the user response is received and it must be processed as a single audio file."]}),"\n"]}),"\n",(0,o.jsx)(n.admonition,{type:"note",children:(0,o.jsxs)(n.p,{children:["To design a good voice agent you must configure these parameters at the ",(0,o.jsx)(n.a,{href:"https://docs.yellow.ai/docs/platform_concepts/studio/build/nodes#32-configure-node-for-a-voice-bot",children:"node level"})," based on the question being asked."]})}),"\n",(0,o.jsx)(n.h3,{id:"21-configure-for-yes-no-response",children:"2.1 Configure for Yes/ No response"}),"\n",(0,o.jsxs)(n.blockquote,{children:["\n",(0,o.jsx)(n.p,{children:"STT engine:: Microsoft and STT mode:: Streaming"}),"\n"]}),"\n",(0,o.jsxs)(n.table,{children:[(0,o.jsx)(n.thead,{children:(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.th,{children:"Parameters"}),(0,o.jsx)(n.th,{children:"Description"}),(0,o.jsx)(n.th,{children:"Min Value"}),(0,o.jsx)(n.th,{children:"Max Value"})]})}),(0,o.jsxs)(n.tbody,{children:[(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.strong,{children:"Recording max duration"})}),(0,o.jsx)(n.td,{children:"Maximum duration after which the recording stops - the user response won't be accepted beyond this time."}),(0,o.jsx)(n.td,{children:"5 seconds"}),(0,o.jsx)(n.td,{children:"60 seconds"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.strong,{children:"Initial silence duration"})}),(0,o.jsx)(n.td,{children:"Acceptable silence duration before a agent user starts speaking."}),(0,o.jsx)(n.td,{children:"5 seconds"}),(0,o.jsx)(n.td,{children:"10 seconds"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.strong,{children:"Final silence duration"})}),(0,o.jsx)(n.td,{children:"Acceptable silence duration after a agent user starts speaking and the agent will have to process the response (Final delay must be greater than expected pauses)."}),(0,o.jsx)(n.td,{children:"0.1 seconds"}),(0,o.jsx)(n.td,{children:"5 seconds"})]})]})]})]})}function c(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(h,{...e})}):h(e)}},28453:(e,n,s)=>{s.d(n,{R:()=>i,x:()=>a});var t=s(96540);const o={},r=t.createContext(o);function i(e){const n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:i(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);