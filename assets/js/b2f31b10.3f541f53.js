"use strict";(self.webpackChunkbenthos=self.webpackChunkbenthos||[]).push([[50541],{603905:function(e,t,n){n.d(t,{Zo:function(){return u},kt:function(){return g}});var a=n(667294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var c=a.createContext({}),p=function(e){var t=a.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},u=function(e){var t=p(e.components);return a.createElement(c.Provider,{value:t},e.children)},s="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,r=e.originalType,c=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),s=p(n),d=o,g=s["".concat(c,".").concat(d)]||s[d]||m[d]||r;return n?a.createElement(g,i(i({ref:t},u),{},{components:n})):a.createElement(g,i({ref:t},u))}));function g(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=n.length,i=new Array(r);i[0]=d;var l={};for(var c in t)hasOwnProperty.call(t,c)&&(l[c]=t[c]);l.originalType=e,l[s]="string"==typeof e?e:o,i[1]=l;for(var p=2;p<r;p++)i[p]=n[p];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}d.displayName="MDXCreateElement"},816707:function(e,t,n){n.r(t),n.d(t,{assets:function(){return u},contentTitle:function(){return c},default:function(){return d},frontMatter:function(){return l},metadata:function(){return p},toc:function(){return s}});var a=n(487462),o=n(263366),r=(n(667294),n(603905)),i=["components"],l={title:"LLM configuration",sidebar_label:"LLM configuration"},c=void 0,p={unversionedId:"platform_concepts/studio/LLM-central-configuration",id:"platform_concepts/studio/LLM-central-configuration",title:"LLM configuration",description:"LLM (Large Language Model) configuration allows you to centrally manage LLM models and accounts for all LLM-powered features, such as the Dynamic chat node, Conversations, Agent AI, and Knowledge Base (KB).",source:"@site/docs/platform_concepts/studio/LLM-central-configuration.md",sourceDirName:"platform_concepts/studio",slug:"/platform_concepts/studio/LLM-central-configuration",permalink:"/docs/platform_concepts/studio/LLM-central-configuration",draft:!1,tags:[],version:"current",frontMatter:{title:"LLM configuration",sidebar_label:"LLM configuration"},sidebar:"platform_concepts",previous:{title:"Automation FAQs",permalink:"/docs/platform_concepts/studio/studio-faqs"},next:{title:"Knowledge base Overview",permalink:"/docs/platform_concepts/studio/kb/overview"}},u={},s=[{value:"Capabilities of LLM configuration",id:"capabilities-of-llm-configuration",level:4},{value:"Access LMM configuration",id:"access-lmm-configuration",level:3},{value:"<strong>From the Settings section</strong>",id:"from-the-settings-section",level:4},{value:"<strong>Directly from the specific LLM-powered module</strong>",id:"directly-from-the-specific-llm-powered-module",level:4},{value:"Manage LLM accounts",id:"manage-llm-accounts",level:3},{value:"Add LLM account",id:"add-llm-account",level:4},{value:"Edit LLM account",id:"edit-llm-account",level:4},{value:"Disconnect LLM account",id:"disconnect-llm-account",level:4},{value:"Edit LLM configuration",id:"edit-llm-configuration",level:4},{value:"FAQ",id:"faq",level:2}],m={toc:s};function d(e){var t=e.components,n=(0,o.Z)(e,i);return(0,r.kt)("wrapper",(0,a.Z)({},m,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"LLM (Large Language Model) configuration allows you to centrally manage LLM models and accounts for all LLM-powered features, such as the Dynamic chat node, Conversations, Agent AI, and Knowledge Base (KB)."),(0,r.kt)("p",null,"This centralized setup allows you to use different accounts and configurations for various LLM modules based on your requirements and eliminates the need for repeated configurations."),(0,r.kt)("h4",{id:"capabilities-of-llm-configuration"},"Capabilities of LLM configuration"),(0,r.kt)("p",null,"With LLM configuration, you can:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Create, edit, switch models, and disconnect LLM accounts."),(0,r.kt)("li",{parentName:"ul"},"Associate LLM accounts at the environment level:",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Two tier environment - Develpoment and Live"),(0,r.kt)("li",{parentName:"ul"},"Three tier environment - Sandbox, Staging, and Production")))),(0,r.kt)("p",null,"The Yellow account is preconfigured with ",(0,r.kt)("strong",{parentName:"p"},"Gpt 4o mini")," account and enabled across all environments by default. The Knowledge Base (KB) uses our proprietary in-house model by default, but you can switch to a different model if needed."),(0,r.kt)("h3",{id:"access-lmm-configuration"},"Access LMM configuration"),(0,r.kt)("p",null,"You can access the LLM configuration in two ways:"),(0,r.kt)("h4",{id:"from-the-settings-section"},(0,r.kt)("strong",{parentName:"h4"},"From the Settings section")),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Go to ",(0,r.kt)("strong",{parentName:"p"},"Settings")," > ",(0,r.kt)("strong",{parentName:"p"},"LLM configuration"),"."),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("img",{parentName:"p",src:"https://i.imgur.com/TgBNvuc.png",alt:null})))),(0,r.kt)("h4",{id:"directly-from-the-specific-llm-powered-module"},(0,r.kt)("strong",{parentName:"h4"},"Directly from the specific LLM-powered module")),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Navigate to the specific LLM-Powered module (Dynamic chat node, Conversations, Agent AI, or Knowledge Base (KB)).")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Click the highlighted icon that you see on that page."),(0,r.kt)("img",{src:"https://i.imgur.com/RKhl6Re.png",alt:"drawing",width:"100%"}),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"This will redirect you to the LLM Configuration page.")))),(0,r.kt)("h3",{id:"manage-llm-accounts"},"Manage LLM accounts"),(0,r.kt)("p",null,"In the LLM configuration section, Super admin can create, edit, and disconnect LLM accounts, switch models across all the environments. "),(0,r.kt)("h4",{id:"add-llm-account"},"Add LLM account"),(0,r.kt)("p",null,"You can view the default Yellow account before adding a new account. If needed, you can create your own LLM account to manage LLM-powered features."),(0,r.kt)("p",null,"To add the LLM account, follow these steps:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Go to ",(0,r.kt)("strong",{parentName:"p"},"Settings")," > ",(0,r.kt)("strong",{parentName:"p"},"LLM configuration"),".")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Click ",(0,r.kt)("strong",{parentName:"p"},"Account list"),"."),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("img",{parentName:"p",src:"https://i.imgur.com/baASqg2.png",alt:null}))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Click ",(0,r.kt)("strong",{parentName:"p"},"+ Add account"),"."),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("img",{parentName:"p",src:"https://imgur.com/mdldiG4.png",alt:"image"}))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"In ",(0,r.kt)("strong",{parentName:"p"},"Give account name"),", enter a name for your LLM account.")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"In ",(0,r.kt)("strong",{parentName:"p"},"LLM provider"),", choose your preferred LLM provider.")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"In ",(0,r.kt)("strong",{parentName:"p"},"API key"),",  get the API key and resource from GPT 3.5 or GPT 4."),(0,r.kt)("p",{parentName:"li"},"  ",(0,r.kt)("img",{parentName:"p",src:"https://i.imgur.com/Ix9UZea.png",alt:null}))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Click ",(0,r.kt)("strong",{parentName:"p"},"Connect"),"."))),(0,r.kt)("h4",{id:"edit-llm-account"},"Edit LLM account"),(0,r.kt)("p",null,"You can update the details of an existing LLM account or provider if needed. You cannot edit/delete the default Yellow account."),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Go to ",(0,r.kt)("strong",{parentName:"p"},"Account list")," > ",(0,r.kt)("strong",{parentName:"p"},"Add account"),".")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Navigate to the account you want to edit and click ",(0,r.kt)("strong",{parentName:"p"},"Edit details"),"."),(0,r.kt)("p",{parentName:"li"}," ",(0,r.kt)("img",{parentName:"p",src:"https://i.imgur.com/2K5tlzc.png",alt:null}))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Add the required account details and click ",(0,r.kt)("strong",{parentName:"p"},"Save"),"."),(0,r.kt)("img",{src:"https://i.imgur.com/WKxnmnU.png",alt:"drawing",width:"80%"}))),(0,r.kt)("h4",{id:"disconnect-llm-account"},"Disconnect LLM account"),(0,r.kt)("p",null,"You cannot disconnect the default Yellow account. However, you can disconnect any other account you have created. "),(0,r.kt)("p",null,"Before disconnecting, ensure another account is created to handle all LLM features."),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Select an alternative account that you want the module to use."),(0,r.kt)("img",{src:"https://i.imgur.com/1gLlCT7.png",alt:"drawing",width:"80%"})),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Go to ",(0,r.kt)("strong",{parentName:"p"},"Account list")," > ",(0,r.kt)("strong",{parentName:"p"},"+ Add account"),"."),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("img",{parentName:"p",src:"https://i.imgur.com/I0wQ2Ta.png",alt:null}))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Navigate to the account you want to disconnect, then click ",(0,r.kt)("strong",{parentName:"p"},"Disconnect")," to remove the account."),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("img",{parentName:"p",src:"https://i.imgur.com/iIbYwb5.png",alt:null})))),(0,r.kt)("h4",{id:"edit-llm-configuration"},"Edit LLM configuration"),(0,r.kt)("p",null,"By default, the Yellow account details are displayed for each environment. However, you can update the existing LLM model or account as needed for each environment."),(0,r.kt)("p",null,"For example, you can set GPT 4.0 model in Staging environment and GPT 3.5 model in Production."),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Navigate to the specific feature where you want to edit the configuration.")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Expand the drop-down menu and click the ",(0,r.kt)("strong",{parentName:"p"},"Edit")," icon corresponding to the specific environment."),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("img",{parentName:"p",src:"https://i.imgur.com/BexB0a9.png",alt:null}))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Update the ",(0,r.kt)("strong",{parentName:"p"},"Account name")," and ",(0,r.kt)("strong",{parentName:"p"},"Model")," as needed."),(0,r.kt)("img",{src:"https://i.imgur.com/B3qS5Xk.png",alt:"drawing",width:"80%"})),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Click ",(0,r.kt)("strong",{parentName:"p"},"Save"),"."))),(0,r.kt)("h2",{id:"faq"},"FAQ"),(0,r.kt)("details",null,(0,r.kt)("summary",null,"Is an LLM Required to Use Yellow.ai?"),(0,r.kt)("div",null,(0,r.kt)("div",null,"No, a Large Language Model (LLM) is not required to use Yellow.ai. The platform offers a wide range of features and functionalities that work independently of LLM integration.",(0,r.kt)("br",null),"However, integrating an LLM can enhance the platform\u2019s capabilities, particularly for handling complex queries, generating dynamic responses, and improving FAQ interactions."),(0,r.kt)("br",null))))}d.isMDXComponent=!0}}]);